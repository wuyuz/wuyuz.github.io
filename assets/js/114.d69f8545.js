(window.webpackJsonp=window.webpackJsonp||[]).push([[114],{460:function(t,s,a){"use strict";a.r(s);var n=a(42),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h3",{attrs:{id:"数据解析"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#数据解析"}},[t._v("#")]),t._v(" 数据解析")]),t._v(" "),a("p",[a("a",{attrs:{href:"https://2.python-requests.org//zh_CN/latest/user/advanced.html#advanced",target:"_blank",rel:"noopener noreferrer"}},[t._v("参考文章"),a("OutboundLink")],1),t._v("：")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("爬虫")])]),t._v(" "),a("li",[a("p",[t._v("爬虫的分类")]),t._v(" "),a("ul",[a("li",[t._v("通用爬虫： 爬取整张网页数据")]),t._v(" "),a("li",[t._v("聚焦爬虫： 爬取部分数据")]),t._v(" "),a("li",[t._v("增量式爬虫： 监测网页更新部分数据")])])]),t._v(" "),a("li",[a("p",[t._v("反爬机制")])]),t._v(" "),a("li",[a("p",[t._v("反反爬策略")])]),t._v(" "),a("li",[a("p",[t._v("robots, UA检测， UA伪装")])]),t._v(" "),a("li",[a("p",[t._v("http&https概念： 服务器和客户端进行数据交互的某种形式")])]),t._v(" "),a("li",[a("p",[t._v("常用的头信息：")]),t._v(" "),a("ul",[a("li",[t._v("User-Agent：请求载体的身份")]),t._v(" "),a("li",[t._v("Conntention: close")]),t._v(" "),a("li",[t._v("Content-Type: json/text...")])])]),t._v(" "),a("li",[a("p",[t._v("https 的加密方式：证书密钥加密")]),t._v(" "),a("ul",[a("li",[t._v("证书：是被应用在https的加密操作中的，该证书是有证书认证机构颁发的，证书中包含了公钥")])])]),t._v(" "),a("li",[a("p",[t._v("requests:")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("get/post:")]),t._v(" "),a("ul",[a("li",[t._v("url")]),t._v(" "),a("li",[t._v("data/params: 对请求参数的封装，（data作用在post中，params作用在get方法中）")]),t._v(" "),a("li",[t._v("headers:UA伪装")])])]),t._v(" "),a("li",[a("p",[t._v("什么是动态加载的数据：由另一个额外的请求到的数据")]),t._v(" "),a("ul",[a("li",[t._v("ajax")]),t._v(" "),a("li",[t._v("js")])])]),t._v(" "),a("li",[a("p",[t._v("如何鉴定页面中是否有动态加载的数据？")]),t._v(" "),a("ul",[a("li",[t._v("局部搜索")]),t._v(" "),a("li",[t._v("全局搜索")])])]),t._v(" "),a("li",[a("p",[t._v("对一个陌生网站进行爬取前的第一步做什么？")]),t._v(" "),a("ul",[a("li",[t._v("确定你要爬取的数据是否为动态加载的")])])])])])]),t._v(" "),a("h3",{attrs:{id:"数据解析-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#数据解析-2"}},[t._v("#")]),t._v(" 数据解析")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("解析： 根据指定的规则对数据进行提取")])]),t._v(" "),a("li",[a("p",[t._v("作用： 实现聚焦爬虫")])]),t._v(" "),a("li",[a("p",[t._v("聚焦爬虫的编码流程：")]),t._v(" "),a("ul",[a("li",[t._v("指定url")]),t._v(" "),a("li",[t._v("发起请求")]),t._v(" "),a("li",[t._v("获取相应数据")]),t._v(" "),a("li",[t._v("数据解析（在通用爬虫基础上多出来了数据解析）")]),t._v(" "),a("li",[t._v("持久化存储")])])]),t._v(" "),a("li",[a("p",[t._v("数据解析的方式")]),t._v(" "),a("ul",[a("li",[t._v("正则解析")]),t._v(" "),a("li",[t._v("bs4解析")]),t._v(" "),a("li",[t._v("xpath解析")]),t._v(" "),a("li",[t._v("pyquery(拓展）")])])]),t._v(" "),a("li",[a("p",[t._v("数据解析的通用原理是什么？")]),t._v(" "),a("ul",[a("li",[t._v("数据解析需要作用在页面源码中（一组html标签组成的）")]),t._v(" "),a("li",[t._v("html的核心作用是什么？\n"),a("ul",[a("li",[t._v("展示数据")])])]),t._v(" "),a("li",[t._v("html是如何展示数据的？\n"),a("ul",[a("li",[t._v("html所要展示的数据一定是被放置在html标签之中，或则在属性中")])])]),t._v(" "),a("li",[t._v("通用原理：\n"),a("ul",[a("li",[t._v("1.标签定位")]),t._v(" "),a("li",[t._v("2.取文本or取属性")])])])])])]),t._v(" "),a("h3",{attrs:{id:"正则实现的数据解析"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#正则实现的数据解析"}},[t._v("#")]),t._v(" 正则实现的数据解析")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("需求： 爬取糗事百科中的糗图")])]),t._v(" "),a("li",[a("p",[t._v("如何爬取图片")])])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 方式二")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" urllib "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" request\nurl "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'https://pic.qiushibaike.com/system/pictures/12217/122176466/medium/I844CD5W6MBJHYYG.jpg'")]),t._v("\n\nrequest"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("urlretrieve"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./456.jpg'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# urllib 就是一个比较老的网络请求的模块，在request模块没有出现之前，请求发送操作都是urllib")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./456.jpg'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("http"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("client"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("HTTPMessage at "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0x1839da405c0")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" requests\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 方式一")]),t._v("\nheaders "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'User-Agent'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36'")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\nurl "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'https://pic.qiushibaike.com/system/pictures/12217/122176466/medium/I844CD5W6MBJHYYG.jpg'")]),t._v("\nimg_data "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" requests"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("url"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("headers"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("headers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("content "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# content 返回byte类型数据，因为图片是byte类型传输")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./123.jpg'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'wb'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("write"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("img_data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("h4",{attrs:{id:"方式1和方式2-对于图片数据爬取得操作最大得不同之处是在哪"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#方式1和方式2-对于图片数据爬取得操作最大得不同之处是在哪"}},[t._v("#")]),t._v(" 方式1和方式2 对于图片数据爬取得操作最大得不同之处是在哪？")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[t._v("答：方式2不可以添加UA伪装机制   \n")])])]),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 爬取糗事百科")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" requests\n\nheaders "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'User-Agent'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36'")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\nurl "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'https://www.qiushibaike.com/pic/'")]),t._v("\npage_text "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" requests"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" headers"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("headers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#分析数据图片都包含在如下得标签之中，那么我们使用正则来匹配出图片地址,注意有回车什么的，需要re.S")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# <div class="thumb">')]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# <a href="/article/122176410" target="_blank">')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v('# <img src="//pic.qiushibaike.com/system/pictures/12217/122176410/medium/KVN1L0WEZCF0MP26.jpg" alt="爱情">')]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# </a>")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#</div>  ")]),t._v("\ndir_name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./qiushi'")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" os\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" os"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("exists"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dir_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    os"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mkdir"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dir_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" re\nex "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('\'<div class="thumb">.*?<img src="(.*?)" alt=.*?</div>\'')]),t._v("\nimg_src_list "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" re"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("findall"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("page_text"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("re"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" src "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" img_src_list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    src "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'https:'")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("src\n    img_name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" src"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    img_path "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" dir_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/'")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("img_name\n    request"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("urlretrieve"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("src"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("img_path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("img_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'下载成功'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[t._v("I844CD5W6MBJHYYG.jpg 下载成功\nEKOKK8LVTIR1N2MH.jpg 下载成功\n")])])]),a("p",[t._v("...")]),t._v(" "),a("h3",{attrs:{id:"爬取多页"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#爬取多页"}},[t._v("#")]),t._v(" 爬取多页")]),t._v(" "),a("ul",[a("li",[t._v("分析：每一个页码对应的url是有共性：https://www.qiushibaike.com/pic/page/%d/")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" requests\n\nheaders "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'User-Agent'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36'")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#分析出所有也页面的共性，只是page后的数字变化了")]),t._v("\nurl "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'https://www.qiushibaike.com/pic/page/%d/'")]),t._v("\n\ndir_name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./qiushis'")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" os\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" re\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" os"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("exists"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dir_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    os"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mkdir"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dir_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" page "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 拿出不同页码的url，进行页码的循环编写")]),t._v("\n    new_text "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" requests"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("url"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v("page"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" headers"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("headers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text\n    \n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#正则匹配出img的src")]),t._v("\n    ex "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('\'<div class="thumb">.*?<img src="(.*?)" alt=.*?</div>\'')]),t._v("\n    img_src_list "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" re"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("findall"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("ex"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("new_text"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("re"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("S"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" src "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" img_src_list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        src "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'https:'")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("src\n        img_name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" src"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        img_path "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" dir_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/'")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("img_name\n        request"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("urlretrieve"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("src"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("img_path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        \n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string-interpolation"}},[a("span",{pre:!0,attrs:{class:"token string"}},[t._v("f'第")]),a("span",{pre:!0,attrs:{class:"token interpolation"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("page"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("页下载成功'")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[t._v("第1页下载成功\n第2页下载成功\n第3页下载成功\n第4页下载成功\n")])])]),a("h2",{attrs:{id:"bs4解析"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#bs4解析"}},[t._v("#")]),t._v(" bs4解析")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("环境的环境")]),t._v(" "),a("ul",[a("li",[t._v("pip install bs4")]),t._v(" "),a("li",[t._v("pip install lxml")])])]),t._v(" "),a("li",[a("p",[t._v("bs4 解析原理：BeautifulSoup是一个解析器")]),t._v(" "),a("ul",[a("li",[t._v("实例化一个BeautifulSoup对象， 并且将即将解析的页面源码数据加载到该对象中")]),t._v(" "),a("li",[t._v("调用BeautifulSoup对象中的相关属性和方法进行标签定位和数据提取")])])]),t._v(" "),a("li",[a("p",[t._v("如何实例化BeautifulSoup对象那？")]),t._v(" "),a("ul",[a("li",[t._v("方式一： BeautifulSoup(fp,,'lxml') # fp通常是获得的一个文件句柄，这种方式专门用作解析本地存储的html文档中的数据")]),t._v(" "),a("li",[t._v("方式二： BeautifulSoup(page_text,'lxml') # 专门用作于将互联网上请求到的页面源码数据进行解析")])])])]),t._v(" "),a("h4",{attrs:{id:"假如我们有以下数据的页面源代码"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#假如我们有以下数据的页面源代码"}},[t._v("#")]),t._v(" 假如我们有以下数据的页面源代码")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v('<head>\n\t<meta charset="UTF-8" />\n\t<title>测试bs4</title>\n</head>\n<body>\n\t<div>\n\t\t<p>百里守约</p>\n\t</div>\n\t<div class="song">\n\t\t<p>李清照</p>\n\t\t<p>王安石</p>\n\t\t<p>苏轼</p>\n\t\t<p>柳宗元</p>\n\t\t<a href="http://www.song.com/" title="赵匡胤" target="_self">\n\t\t\t<span>this is span</span>\n\t\t宋朝是最强大的王朝，不是军队的强大，而是经济很强大，国民都很有钱</a>\n\t\t<a href="" class="du">总为浮云能蔽日,长安不见使人愁</a>\n\t\t<img src="http://www.baidu.com/meinv.jpg" alt="" />\n\t</div>\n\t<div class="tang">\n\t\t<ul>\n\t\t\t<li><a href="http://www.baidu.com" title="qing">清明时节雨纷纷,路上行人欲断魂,借问酒家何处有,牧童遥指杏花村</a></li>\n\t\t\t<li><a href="http://www.163.com" title="qin">秦时明月汉时关,万里长征人未还,但使龙城飞将在,不教胡马度阴山</a></li>\n\t\t\t<li><a href="http://www.126.com" alt="qi">岐王宅里寻常见,崔九堂前几度闻,正是江南好风景,落花时节又逢君</a></li>\n\t\t\t<li><a href="http://www.sina.com" class="du">杜甫</a></li>\n\t\t\t<li><a href="http://www.dudu.com" class="du">杜牧</a></li>\n\t\t\t<li><b>杜小月</b></li>\n\t\t\t<li><i>度蜜月</i></li>\n\t\t\t<li><a href="http://www.haha.com" id="feng">凤凰台上凤凰游,凤去台空江自流,吴宫花草埋幽径,晋代衣冠成古丘</a></li>\n\t\t</ul>\n\t</div>\n</body>\n</html>\n')])])]),a("h3",{attrs:{id:"标签定位"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#标签定位"}},[t._v("#")]),t._v(" 标签定位")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("soup.tagName: 定位到第一个TagName标签，返回的是单数")])]),t._v(" "),a("li",[a("p",[t._v("属性定位：soup.find('tagName',attrName='value'),返回也是一个单数")]),t._v(" "),a("ul",[a("li",[t._v("fund_all:和find用法一致，但是返回值是一个复数")])])]),t._v(" "),a("li",[a("p",[t._v("选择器定位：select('选择器'), 返回值是列表")]),t._v(" "),a("ul",[a("li",[t._v("标签、类、id、层级选择器（>:一个层级，空格表示多个层级）")])])])]),t._v(" "),a("h3",{attrs:{id:"提取数据"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#提取数据"}},[t._v("#")]),t._v(" 提取数据")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("取文本：")]),t._v(" "),a("ul",[a("li",[t._v("tag.string ：获取标签中的直系的文本内容")]),t._v(" "),a("li",[t._v("tag.text： 获取标签中所有文本内容，包括直系")])])]),t._v(" "),a("li",[a("p",[t._v("取属性：")]),t._v(" "),a("ul",[a("li",[t._v("tag['attrName']")])])])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 方式一：要获得文件句柄")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" bs4 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" BeautifulSoup\n\nfp "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./test.html'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'r'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("encoding"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'utf-8'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nsoup "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" BeautifulSoup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("fp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'lxml'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 将fp中的源码加载到soup对象中")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#标签定位")]),t._v("\nsoup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("p  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#p>百里守约</p>,定位到第一个tagName标签")]),t._v("\nsoup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'div'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#<div><p>百里守约</p></div>  也是返回第一个标签")]),t._v("\n\nsoup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'div'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("class_"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'song'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 返回<div class='song'> div中的内容，也是一个单数，可以通过class_、id等查找特定的标签")]),t._v("\nsoup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find_all"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'div'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("class_"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'song'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# find_all 和find用法一致，但是返回的是一个列表，也就是说find_all可能返回的是复数")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 选择器定位")]),t._v("\nsoup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("select"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.tang'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#选择带有.tang类的标签")]),t._v("\nsoup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("select"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'#feng'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#选择id为feng的标签")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#层级定位")]),t._v("\nsoup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("select"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.tang > ul > li'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 放回的是tang类下ul下的所有li，返回一个列表")]),t._v("\nsoup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("select"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.tang li'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 空格表示可以多个层级相隔，>表示一个层级相隔")]),t._v("\n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[t._v('[<li><a href="http://www.baidu.com" title="qing">清明时节雨纷纷,路上行人欲断魂,借问酒家何处有,牧童遥指杏花村</a></li>,\n <li><a href="http://www.163.com" title="qin">秦时明月汉时关,万里长征人未还,但使龙城飞将在,不教胡马度阴山</a></li>,\n <li><a alt="qi" href="http://www.126.com">岐王宅里寻常见,崔九堂前几度闻,正是江南好风景,落花时节又逢君</a></li>,\n <li><a class="du" href="http://www.sina.com">杜甫</a></li>,\n <li><a class="du" href="http://www.dudu.com">杜牧</a></li>,\n <li><b>杜小月</b></li>,\n <li><i>度蜜月</i></li>,\n <li><a href="http://www.haha.com" id="feng">凤凰台上凤凰游,凤去台空江自流,吴宫花草埋幽径,晋代衣冠成古丘</a></li>]\n')])])]),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 取数据：定位标签就是为了去数据")]),t._v("\nli_6 "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("select"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.tang > ul > li'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#<li><i>度蜜月</i></li>")]),t._v("\ni_tag "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" li_6"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("i  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#去出li_6中的i标签")]),t._v("\ni_tag"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#'度蜜月'")]),t._v("\ni_tag"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("string  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#'度蜜月'")]),t._v("\ni_tag"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("strings"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("__next__"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# '度蜜月' strings放回的是一个生成器 ")]),t._v("\n\ndiv "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'div'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("class_"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'tang'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果我想要此div中的所有文本内容")]),t._v("\ndiv"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 获得div中所有的文本，非直系，就是不是自己儿子辈的")]),t._v("\ndiv"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("string  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 获取不到数据，因为div的儿子没有文本，直系")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 取属性")]),t._v("\nsoup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'a'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("id")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'feng'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'href'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#'http://www.haha.com'")]),t._v("\n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[t._v("'http://www.haha.com'\n")])])]),a("h3",{attrs:{id:"爬取小说"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#爬取小说"}},[t._v("#")]),t._v(" 爬取小说")]),t._v(" "),a("ul",[a("li",[t._v("爬取网站：http://www.shicimingju.com/book/sanguoyanyi.html\n"),a("ul",[a("li",[t._v("确认爬取的数据是否是动态加载的，显然不是")]),t._v(" "),a("li",[t._v("确认爬取数据：爬取章节名称和章节内容")]),t._v(" "),a("li",[t._v("在首页不仅要解析出章节名称，还有解析出章节rul")])])])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 在首页中解析出章节名称&每一章节详细页url")]),t._v("\nurl "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'http://www.shicimingju.com/book/sanguoyanyi.html'")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" requests\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" bs4 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" BeautifulSoup\n\nheaders "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'User-Agent'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36'")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\npage_text "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" requests"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("headers"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("headers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#因为是文本，所以使用text、图片等要用content")]),t._v("\nsoup "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" BeautifulSoup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("page_text"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'lxml'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 分析可得：每个li标签中包含着每一章的rul，而直系内容就是每一章的名称啊，select的用法很旷阔")]),t._v("\na_list "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("select"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.book-mulu > ul > li > a'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\nfp "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'sanguo.txt'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'w'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("encoding"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'utf-8'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" a "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" a_list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    detail_url "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'http://www.shicimingju.com'")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'href'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    chap_title "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" a"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("string "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 直系文本")]),t._v("\n    \n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 对章节详情页的url发起请求，解析详情页中的章节内容,判断详情页没有动态加载的数据")]),t._v("\n    detail_page_text "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" requests"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("detail_url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("headers"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("headers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 重新实例化soup")]),t._v("\n    new_soup "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" BeautifulSoup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("detail_page_text"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'lxml'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  \n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 找到放文本的div，列出所有的文本")]),t._v("\n    chap_content "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" new_soup"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("find"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'div'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("class_"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'chapter_content'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text\n    fp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("write"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("chap_title"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("':'")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("chap_content"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'\\n'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("chap_title"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'爬取成功'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[t._v("第一回·宴桃园豪杰三结义  斩黄巾英雄首立功 爬取成功\n第二回·张翼德怒鞭督邮    何国舅谋诛宦竖 爬取成功\n第三回·议温明董卓叱丁原  馈金珠李肃说吕布 爬取成功\n第四回·废汉帝陈留践位    谋董贼孟德献刀 爬取成功\n....\n")])])]),a("h2",{attrs:{id:"xpath解析"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#xpath解析"}},[t._v("#")]),t._v(" xpath解析")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("环境的安装：pip install lxml")])]),t._v(" "),a("li",[a("p",[t._v("xpath的解析原理")]),t._v(" "),a("ul",[a("li",[t._v("实例化一个etree类型的对象，且将页面源码数据加载到该对象中")]),t._v(" "),a("li",[t._v("需要调用该对象的xpath方式结合着不同形式的xpath表达式进行标签定位和数据提取")])])]),t._v(" "),a("li",[a("p",[t._v("etree 对象的实例化的两种方式：")]),t._v(" "),a("ul",[a("li",[t._v("etree.parse(fileName)  将本地fileName文件加载成etree对象")]),t._v(" "),a("li",[t._v("etree.HTML(page_text)  将网页上请求的数据加载成etree对象")])])]),t._v(" "),a("li",[a("p",[t._v("etree对象的xpath方法返回的永远是一个列表")])])]),t._v(" "),a("h3",{attrs:{id:"基于标签定位的xpath"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#基于标签定位的xpath"}},[t._v("#")]),t._v(" 基于标签定位的xpath")]),t._v(" "),a("ul",[a("li",[t._v("在xpath表达式中最左侧的/表示含义是说，当前定位的标签必须从根节点开始进行定位，也就是说左侧只有一个/，则后面必须紧跟html")]),t._v(" "),a("li",[t._v("xpath表达式中最左侧的//表示可以从任意位置进行标签定位")]),t._v(" "),a("li",[t._v("xpath表达式中非最左侧的//表示的是多个层级跨越的意思")]),t._v(" "),a("li",[t._v("xpath表达式中最左侧的/表示的是一个层级的意思")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" lxml "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" etree\ntree "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" etree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./test.html'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#将一个文本内容加载成etree对象后，我们就可以调用对象的xpath函数，通过树状结构层级查找元素标签")]),t._v("\ntree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/html/head/meta'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#[<Element meta at 0x290d200e448>] ---\x3e 绝对路径查找，")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#通过索引取出对应的对象")]),t._v("\ntree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/html/head/meta'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#<Element meta at 0x290d1f623c8>")]),t._v("\n\ntree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'//meta'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#<Element meta at 0x290d1cb3dc8>  ----\x3e 相对路径查找，将整个页面源码中所有的meta进行定位 //表示")]),t._v("\n\ntree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/html//meta'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#<Element meta at 0x290d19dff08>")]),t._v("\n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[t._v("<Element meta at 0x290d19dff08>\n")])])]),a("h3",{attrs:{id:"基于属性定位的xpath"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#基于属性定位的xpath"}},[t._v("#")]),t._v(" 基于属性定位的xpath")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("属性定位： //tagName[@arrtName='value']")])]),t._v(" "),a("li",[a("p",[t._v("索引定位： //tagName/li[3]")])])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("tree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'//div'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#同时列出三个对象 [<Element div at 0x290d1954248>,[<Element div at 0x290d1954248>],[<Element div at 0x290d1954248>]]")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#属性定位")]),t._v("\ntree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'//div[@class=\"song\"]'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# [<Element div at 0x290d1954248>] 列出满足class=song的div")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 索引定位")]),t._v("\ntree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'//div[@class=\"tang\"]/ul/li'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 列表中多个对象")]),t._v("\ntree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'//div[@class=\"tang\"]/ul/li[1]'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 1写在里面表示第一个，从1开始计数")]),t._v("\ntree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'//div[@class=\"tang\"]/ul/li'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[t._v("[<Element li at 0x290d21c2188>]\n")])])]),a("h3",{attrs:{id:"提取数据-2"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#提取数据-2"}},[t._v("#")]),t._v(" 提取数据")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("取文本：")]),t._v(" "),a("ul",[a("li",[t._v("/text(): 取直系的文本内容")]),t._v(" "),a("li",[t._v("//text(): 取所有的文本内容")])])]),t._v(" "),a("li",[a("p",[t._v("取属性：")]),t._v(" "),a("ul",[a("li",[t._v("tag/@attrName: tag是我们匹配到的标签，通过@方式取值")])])])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 取文本")]),t._v("\ntree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'//p[1]/text()'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 取出每个div的第一个p标签的文本")]),t._v("\ntree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'//p[1]'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#[<Element p at 0x290d2213d08>, <Element p at 0x290d20a6ac8>]")]),t._v("\n\ntree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'//div[@class=\"song\"]//text()'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 取出div下所有文本")]),t._v("\n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[t._v("['\\n\\t\\t',\n '李清照',\n '\\n\\t\\t',\n '王安石',\n '\\n\\t\\t',\n '苏轼',\n '\\n\\t\\t',\n '柳宗元',\n '\\n\\t\\t',\n '\\n\\t\\t\\t',\n 'this is span',\n '\\n\\t\\t宋朝是最强大的王朝，不是军队的强大，而是经济很强大，国民都很有钱',\n '\\n\\t\\t',\n '总为浮云能蔽日,长安不见使人愁',\n '\\n\\t\\t',\n '\\n\\t']\n")])])]),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#取属性")]),t._v("\ntree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'//a[@id=\"feng\"]/@href'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 先根据属性查出对象，再通过@符号取值")]),t._v("\n\ntree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'//a[@title=\"赵匡胤\"]/@href'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#['http://www.song.com/']")]),t._v("\n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[t._v("['http://www.song.com/']\n")])])]),a("h3",{attrs:{id:"爬取boss的招聘信息"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#爬取boss的招聘信息"}},[t._v("#")]),t._v(" 爬取boss的招聘信息")]),t._v(" "),a("ul",[a("li",[t._v("岗位名称")]),t._v(" "),a("li",[t._v("公司名称")]),t._v(" "),a("li",[t._v("薪资")]),t._v(" "),a("li",[t._v("岗位描述")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" requests\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" bs4 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" BeautifulSoup\n\nheaders "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'User-Agent'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果获取的page_text中的数据不是正常的response数据，且在爬取之前访问过该网址，则可能记录 cookie,所以必须携带cookie访问")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'cookie'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'lastCity=101010100; __c=1566901179; __g=-; Hm_lvt_194df3105ad7148dcf2b98a91b5e727a=1566901179; _uab_collina=156690117919419065884495; __l=l=%2Fwww.zhipin.com%2F&r=https%3A%2F%2Fwww.baidu.com%2Flink%3Furl%3Dhn6W0tys1Ol5M08yMufJbxta0Zk092ycaDfmbIEUjJwy4tlSJ2O_qQvMIExRX8ps%26wd%3D%26eqid%3Dbc612faf000e4860000000025d6503b9&friend_source=0&friend_source=0; __zp_stoken__=91d9QItKEtUk5dMMnDG7lwzq8sVSYJawCtdfoOUdRiRv7yPRrk5R5sa3VrzsQn9ZL47h1%2FWTcrObgrgz4DnfBb0DxA%3D%3D; __a=93010145.1566901179..1566901179.3.1.3.3; Hm_lpvt_194df3105ad7148dcf2b98a91b5e727a=1566901385'")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\nurl "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'https://www.zhipin.com/job_detail/?query=%E7%88%AC%E8%99%AB&city=101010100&industry=&position='")]),t._v("\n\npage_text "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" requests"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" headers"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("headers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text\n\ntree "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" etree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("HTML"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("page_text"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 这里获取的是网页上传来的text，所以使用HTML")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# # xpath 返回的每一个对象也是及继承了tree的，所以也有xpath的方法")]),t._v("\nli_list "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'//div[@class=\"job-list\"]/ul/li'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" li "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" li_list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#li也有xpath的方法，需要将li表示的局部页面源码数据进行提取")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 如果xpath表达式被作用在了循环中，表达式要以./或者.//开头")]),t._v("\n    detail_url "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'https://www.zhipin.com'")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" li"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.//div[@class=\"info-primary\"]/h3/a/@href'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#注意子对象li，要匹配本身的内容就的以.//开始")]),t._v("\n    job_title "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" li"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.//div[@class=\"info-primary\"]/h3/a/div/text()'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    salary "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" li"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.//div[@class=\"info-primary\"]/h3/a/span/text()'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    \n    company "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" li"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.//div[@class=\"info-company\"]/div/h3/a/text()'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    \n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#对详情页的url发请求解析出岗位描述")]),t._v("\n    detail_page_text "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" requests"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("detail_url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("headers"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("headers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text\n    new_tree "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" etree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("HTML"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("detail_page_text"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    job_desc "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" new_tree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'//div[@class=\"text\"]//text()'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    job_desc "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("join"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("job_desc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("job_title"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("job_desc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("company"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("salary"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[t._v("爬虫工程师 \n                                    岗位职责：1、负责公司的爬虫核心技术研究以及爬虫策略优化；2、根据业务需求，实现大规模文本、图片、视频数据抓取、清洗、存储等工作；3、对数据质量负责，提供数据分析报告，优化数据应用架构，支持产品研发。岗位要求：1、计算机、数学或统计等相关专业本科及以上学历，2年以上数据相关工作经验；2、熟悉linux平台，掌握Python/JAVA或某种编程语言；3、熟悉基于正则表达式、CSS、http协议、ml等的网页信息抽取技术；4、精通常用的爬虫技术及架构，并能快速实现；5、熟悉多线程编程、分布式计算，有分布式系统使用经验。6、具备良好的编程习惯和算法基础，具有钻研精神；7、对数据驱动业务有深入理解，对数据与业务方面有足够的敏感性，独立思考能力和逻辑分析能力强。\n                                \n                                        汽车之家（NYSE：ATHM）成立于2005年，是中国领先的汽车互联网平台——为汽车消费者提供选车、买车、用车、换车等所有环节的全面、准确、快捷的一站式服务。我们致力于通过产品服务、数据技术、生态规则和资源为用户和客户赋能，建设“车媒体、车电商、车金融、车\n")])])]),a("h3",{attrs:{id:"另一种较为通用的xpath表达式的使用形式"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#另一种较为通用的xpath表达式的使用形式"}},[t._v("#")]),t._v(" 另一种较为通用的xpath表达式的使用形式")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("爬取糗事百科的段子内容和作者名称，找一个有匿名用户发表文字的网页url")]),t._v(" "),a("ul",[a("li",[t._v("遇到匿名用户时，由于没有了a标签，会发生报错，我们必须进行处理\n"),a("ul",[a("li",[t._v("使用 '|' 或在在div中对多个条件进行筛选，判断，用于解析不规则布局的页面")])])])])])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("url"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'https://www.qiushibaike.com/text/page/2/'")]),t._v("\nheaders "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'User-Agent'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" lxml "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" etree\npage_text "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" requests"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("headers"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("headers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text\npage_text\ntree "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" etree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("HTML"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("page_text"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#发现每个文字内容都在这个div中")]),t._v("\ndiv_list "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'//div[@id=\"content-left\"]/div'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" div "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" div_list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#当解析到匿名用户是，结构发生裱花没有a标签会报错out of range，必须处理匿名用户的情况使用管道符处理匿名情况的情况，或者叫或关系匹配")]),t._v("\n    author "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" div"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./div[1]/a[2]/h2/text() | ./div[1]/span[2]/h2/text()'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    content_list "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" div"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.//div[@class=\"content\"]/span//text()'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    content "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("join"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("content_list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("author"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("content_list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[t._v("十亿精兵总统领\n ['\\n\\n\\n连载小插曲', '小时候村里的孩子多，又没啥可玩的，个个都是淘气包，到谁家，谁家大人都头疼，多少都会搞点破坏，所以家长们统一口径，要玩就出去玩，不准到家里玩！', '这不就到了一年一度的寒假期间，小伙伴们早早写好了作业，就等着撒欢玩。', '终于机会来了，天下起了鹅毛大雪，我们相约去打雪仗，从村东头打到村西头，又从西头打到东头，打来打去感觉有点枯燥了，天也有点黑了，就有人提议我们去堆个大雪人吧，大家都表示同意，可去哪里堆是个问题。', '这时候村长家的公子歌歌哒说，我们去大队部吧，那里面地方大。有领导的孩子带头，\\n…\\n', '查看全文']\n")])])]),a("p",[t._v("...")]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[t._v("爆笑菌boy\n ['\\n\\n\\n老婆出差，我给老婆发短信：宝贝，发张私密照呗！一分钟不到，收到一张照片，老婆一丝不挂，左手付墙，右手撩头发。整个照片画面和谐，可我就感到有那么一点不对，又说不上来呢……\\n\\n']\n匿名用户 ['\\n\\n\\n为啥现在感觉对象亲我，就想小鸡啄米呢\\n\\n']\n")])])]),a("h3",{attrs:{id:"解决中文乱码问题"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#解决中文乱码问题"}},[t._v("#")]),t._v(" 解决中文乱码问题")]),t._v(" "),a("ul",[a("li",[a("p",[t._v("爬取彼岸图网,对应的url：http://pic.netbian.com/4kmeishi/")])]),t._v(" "),a("li",[a("p",[t._v("获取图片和相应的名称")])]),t._v(" "),a("li",[a("p",[t._v("分析： 第一页url：http://pic.netbian.com/4kmeishi/  其他页网页：http://pic.netbian.com/4kmeishi/index_2.html  页码改变")])])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 制定的通用的url模板")]),t._v("\nurl "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'http://pic.netbian.com/4kmeishi/index_%d.html'")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" page "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" page "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        new_url "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'http://pic.netbian.com/4kmeishi/'")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        new_url "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" url"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v("page\n    page_text "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" requests"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("new_url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("headers"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("headers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#     print(page_text)  # 打印源码，发现文字乱码，并且这里使用response.encoding = 'utf-8'不能解决问题")]),t._v("\n    tree "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" etree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("HTML"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("page_text"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    li_list "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'//*[@id=\"main\"]/div[3]/ul/li'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" li "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" li_list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        img_src "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'http://pic.netbian.com'")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("li"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./a/img/@src'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        img_name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" li"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./a/b/text()'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        img_name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" img_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("encode"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'iso-8859-1'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("decode"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'gbk'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#iso-8859-1是一个字符集，但是比utf8更多包括的字符")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("img_src"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" img_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[t._v("http://pic.netbian.com/uploads/allimg/181223/205433-154556967383ec.jpg 2019新年快乐 丰盛美食 \nhttp://pic.netbian.com/uploads/allimg/180726/192028-153260402827c6.jpg 健康的水果和蔬菜4k壁纸\nhttp://pic.netbian.com/uploads/allimg/171226/100652-1514254012c82a.jpg 猕猴桃,水果,蔬菜沙拉,西\nhttp://pic.netbian.com/uploads/allimg/171219/191722-15136822427df2.jpg 松饼,甜点,薄荷,5k图片\nhttp://pic.netbian.com/uploads/allimg/171212/195515-1513079715ce91.jpg 早餐麦片,牛奶,水果,草莓\nhttp://pic.netbian.com/uploads/allimg/171212/185016-15130758160ca1.jpg 意大利烤宽面条4k美食壁\n")])])]),a("p",[t._v("...")]),t._v(" "),a("h3",{attrs:{id:"爬取站长素材的高清图片-并保存到本地-url-http-sc-chinaz-com-tag-tupian-yazhoumeinv-html"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#爬取站长素材的高清图片-并保存到本地-url-http-sc-chinaz-com-tag-tupian-yazhoumeinv-html"}},[t._v("#")]),t._v(" 爬取站长素材的高清图片，并保存到本地，url：http://sc.chinaz.com/tag_tupian/YaZhouMeiNv.html")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" requests"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("os\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" bs4 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" BeautifulSoup\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" lxml "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" etree\n\nurl "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'http://sc.chinaz.com/tag_tupian/YaZhouMeiNv.html'")]),t._v("\n\nheaders "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'User-Agent'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\npage_text "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" requests"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" headers"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("headers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text\ntree "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" etree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("HTML"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("page_text"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\nimg_list "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'//div[@id=\"container\"]/div'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\ndir_name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'meinv'")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" os"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("exists"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dir_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    os"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mkdir"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dir_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" img "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" img_list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    img_info "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" img"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./p/a/text()'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    img_info"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" img_info"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("encode"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'iso-8859-1'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("decode"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'utf-8'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    detail_img "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" img"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./p/a/@href'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    new_page "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" requests"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("detail_img"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("headers"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("headers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text\n    new_tree "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" etree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("HTML"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("new_page"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    img_url "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" new_tree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('\'//div[@class="down_wrap"]//div[@class="imga"]/a/@href\'')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        \n    img_name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" img_url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    file_path "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" dir_name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/'")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" img_name\n    fp "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("file_path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'wb'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("file")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" requests"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("img_url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("headers"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("headers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("content\n    fp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("write"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("file")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    fp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    \n    \n")])])]),a("h3",{attrs:{id:"爬取站长获取模板-url-http-sc-chinaz-com-jianli-free-html-qq-pf-to-pcqq-c2c"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#爬取站长获取模板-url-http-sc-chinaz-com-jianli-free-html-qq-pf-to-pcqq-c2c"}},[t._v("#")]),t._v(" 爬取站长获取模板，url:http://sc.chinaz.com/jianli/free.html?qq-pf-to=pcqq.c2c")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" requests\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" re \n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" lxml "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" etree\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" random\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" bs4 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" BeautifulSoup\n\nheaders "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'User-Agent'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.100 Safari/537.36'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\nurl "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'http://sc.chinaz.com/jianli/free_%d.html'")]),t._v("\n\n\ndir_name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'moban'")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("not")]),t._v(" os"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("path"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("exists"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dir_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    os"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mkdir"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("dir_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" page "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("range")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("6")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    \n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" page "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        new_url "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'http://sc.chinaz.com/jianli/free.html'")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        new_url "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" url"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("%")]),t._v("page\n\n    page_text "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" requests"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("new_url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("headers"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("headers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text\n\n    tree "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" etree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("HTML"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("page_text"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n\n    m_list "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" tree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'//div[@id=\"container\"]/div'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" m "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" m_list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n\n        detail_htm "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./a/@href'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        m_name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" m"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./a/img/@alt'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        m_name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" m_name"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("encode"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'iso-8859-1'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("decode"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'utf-8'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 跨页面")]),t._v("\n        detail_page "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" requests"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("detail_htm"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("headers"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("headers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("text\n        new_tree "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" etree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("HTML"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("detail_page"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n        li_list "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" new_tree"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'//div[@id=\"down\"]/div[2]/ul/li'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n        num "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" random"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("randint"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("len")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("li_list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        new_li "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" li_list"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("num"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n        new_url "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" new_li"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'./a/@href'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"src="')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" new_url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            xxx "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" re"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("findall"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'(jianli[\\d]+)'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("new_url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            new_url "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string-interpolation"}},[a("span",{pre:!0,attrs:{class:"token string"}},[t._v("f'http://downsc.chinaz.net/Files/DownLoad/jianli/201908/")]),a("span",{pre:!0,attrs:{class:"token interpolation"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("xxx"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v(".rar'")])]),t._v("\n\n        filename "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" dir_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'/'")]),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("m_name"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'.rar'")]),t._v("\n\n\n        data "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" requests"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("get"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("new_url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("headers"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("headers"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("content\n\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("with")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("open")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("filename"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'wb'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("as")]),t._v(" f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            f"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("write"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("data"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string-interpolation"}},[a("span",{pre:!0,attrs:{class:"token string"}},[t._v("f'第")]),a("span",{pre:!0,attrs:{class:"token interpolation"}},[a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("page"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")])]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("页抓取成功！'")])]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("div",{staticClass:"language- extra-class"},[a("pre",[a("code",[t._v("第1页抓取成功！\n第2页抓取成功！\n第3页抓取成功！\n第4页抓取成功！\n第5页抓取成功！\n")])])])])}),[],!1,null,null,null);s.default=e.exports}}]);