<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Scrapy运用与总结 | 独角兕大王</title>
    <meta name="generator" content="VuePress 1.5.4">
    
    <meta name="description" content="">
    <link rel="preload" href="/assets/css/0.styles.ccac5a78.css" as="style"><link rel="preload" href="/assets/js/app.51f2f156.js" as="script"><link rel="preload" href="/assets/js/2.8911ec45.js" as="script"><link rel="preload" href="/assets/js/107.7331bbca.js" as="script"><link rel="prefetch" href="/assets/js/10.6948c28b.js"><link rel="prefetch" href="/assets/js/100.276864ee.js"><link rel="prefetch" href="/assets/js/101.447ab1c7.js"><link rel="prefetch" href="/assets/js/102.f5b3c71d.js"><link rel="prefetch" href="/assets/js/103.16474d4b.js"><link rel="prefetch" href="/assets/js/104.ed58aef3.js"><link rel="prefetch" href="/assets/js/105.045203cd.js"><link rel="prefetch" href="/assets/js/106.be359e0b.js"><link rel="prefetch" href="/assets/js/108.76e1c800.js"><link rel="prefetch" href="/assets/js/109.e82166f3.js"><link rel="prefetch" href="/assets/js/11.d4ec37c8.js"><link rel="prefetch" href="/assets/js/110.4144755a.js"><link rel="prefetch" href="/assets/js/111.5864ab53.js"><link rel="prefetch" href="/assets/js/112.ca2aee84.js"><link rel="prefetch" href="/assets/js/113.641e7765.js"><link rel="prefetch" href="/assets/js/114.d69f8545.js"><link rel="prefetch" href="/assets/js/115.1b6a9f89.js"><link rel="prefetch" href="/assets/js/116.dde2c44e.js"><link rel="prefetch" href="/assets/js/117.4e79498c.js"><link rel="prefetch" href="/assets/js/12.7aac9c8d.js"><link rel="prefetch" href="/assets/js/13.abf127cd.js"><link rel="prefetch" href="/assets/js/14.aa4413a7.js"><link rel="prefetch" href="/assets/js/15.11a64e5b.js"><link rel="prefetch" href="/assets/js/16.f2d9a882.js"><link rel="prefetch" href="/assets/js/17.11c5bb7f.js"><link rel="prefetch" href="/assets/js/18.a522877b.js"><link rel="prefetch" href="/assets/js/19.6f31a972.js"><link rel="prefetch" href="/assets/js/20.b546c54e.js"><link rel="prefetch" href="/assets/js/21.6d055b7f.js"><link rel="prefetch" href="/assets/js/22.c48feceb.js"><link rel="prefetch" href="/assets/js/23.69941f78.js"><link rel="prefetch" href="/assets/js/24.6126dfc2.js"><link rel="prefetch" href="/assets/js/25.3475449c.js"><link rel="prefetch" href="/assets/js/26.96bb4643.js"><link rel="prefetch" href="/assets/js/27.da610e5d.js"><link rel="prefetch" href="/assets/js/28.b24ec15c.js"><link rel="prefetch" href="/assets/js/29.ec8af553.js"><link rel="prefetch" href="/assets/js/3.bec5f768.js"><link rel="prefetch" href="/assets/js/30.2e780db1.js"><link rel="prefetch" href="/assets/js/31.464c36ed.js"><link rel="prefetch" href="/assets/js/32.ad7d37c2.js"><link rel="prefetch" href="/assets/js/33.722f1ec5.js"><link rel="prefetch" href="/assets/js/34.8448d0fd.js"><link rel="prefetch" href="/assets/js/35.e5168ac9.js"><link rel="prefetch" href="/assets/js/36.edc404f1.js"><link rel="prefetch" href="/assets/js/37.5807602e.js"><link rel="prefetch" href="/assets/js/38.a519c89a.js"><link rel="prefetch" href="/assets/js/39.89af1b9a.js"><link rel="prefetch" href="/assets/js/4.5ed19beb.js"><link rel="prefetch" href="/assets/js/40.6c653db9.js"><link rel="prefetch" href="/assets/js/41.bc3b8b69.js"><link rel="prefetch" href="/assets/js/42.a0a02d9b.js"><link rel="prefetch" href="/assets/js/43.62f344e3.js"><link rel="prefetch" href="/assets/js/44.a7fd9d68.js"><link rel="prefetch" href="/assets/js/45.729c1c39.js"><link rel="prefetch" href="/assets/js/46.5b924aea.js"><link rel="prefetch" href="/assets/js/47.f3990404.js"><link rel="prefetch" href="/assets/js/48.f591f360.js"><link rel="prefetch" href="/assets/js/49.f7f213ad.js"><link rel="prefetch" href="/assets/js/5.2c5d28b5.js"><link rel="prefetch" href="/assets/js/50.b9ca2762.js"><link rel="prefetch" href="/assets/js/51.93672ee6.js"><link rel="prefetch" href="/assets/js/52.fb21314a.js"><link rel="prefetch" href="/assets/js/53.65343ccc.js"><link rel="prefetch" href="/assets/js/54.8081227d.js"><link rel="prefetch" href="/assets/js/55.e207659e.js"><link rel="prefetch" href="/assets/js/56.bde381df.js"><link rel="prefetch" href="/assets/js/57.f8eceb45.js"><link rel="prefetch" href="/assets/js/58.bef70bfd.js"><link rel="prefetch" href="/assets/js/59.7ab7562d.js"><link rel="prefetch" href="/assets/js/6.fc65a1ac.js"><link rel="prefetch" href="/assets/js/60.f40ac3ca.js"><link rel="prefetch" href="/assets/js/61.d2b463ab.js"><link rel="prefetch" href="/assets/js/62.cfdf1bcf.js"><link rel="prefetch" href="/assets/js/63.1e45ce59.js"><link rel="prefetch" href="/assets/js/64.a98fe86e.js"><link rel="prefetch" href="/assets/js/65.0234d7c5.js"><link rel="prefetch" href="/assets/js/66.724906f0.js"><link rel="prefetch" href="/assets/js/67.7806fda6.js"><link rel="prefetch" href="/assets/js/68.9f227dae.js"><link rel="prefetch" href="/assets/js/69.fdbc56ac.js"><link rel="prefetch" href="/assets/js/7.284de54e.js"><link rel="prefetch" href="/assets/js/70.04a9cc03.js"><link rel="prefetch" href="/assets/js/71.a6fa1dd9.js"><link rel="prefetch" href="/assets/js/72.2f8e3aa0.js"><link rel="prefetch" href="/assets/js/73.9bbb0cb6.js"><link rel="prefetch" href="/assets/js/74.9f122255.js"><link rel="prefetch" href="/assets/js/75.75e1fbd8.js"><link rel="prefetch" href="/assets/js/76.60ff3c3e.js"><link rel="prefetch" href="/assets/js/77.39a253ae.js"><link rel="prefetch" href="/assets/js/78.0e49712f.js"><link rel="prefetch" href="/assets/js/79.5f9c24a0.js"><link rel="prefetch" href="/assets/js/8.5c21a4cc.js"><link rel="prefetch" href="/assets/js/80.f826f188.js"><link rel="prefetch" href="/assets/js/81.b8995ea7.js"><link rel="prefetch" href="/assets/js/82.e9bf63e0.js"><link rel="prefetch" href="/assets/js/83.e3a00749.js"><link rel="prefetch" href="/assets/js/84.b940927c.js"><link rel="prefetch" href="/assets/js/85.ad46a9b2.js"><link rel="prefetch" href="/assets/js/86.190e0071.js"><link rel="prefetch" href="/assets/js/87.5f9eb9ef.js"><link rel="prefetch" href="/assets/js/88.cfaf7469.js"><link rel="prefetch" href="/assets/js/89.e64cc32c.js"><link rel="prefetch" href="/assets/js/9.0723805d.js"><link rel="prefetch" href="/assets/js/90.805edabe.js"><link rel="prefetch" href="/assets/js/91.6a1ab3f7.js"><link rel="prefetch" href="/assets/js/92.04ecd01e.js"><link rel="prefetch" href="/assets/js/93.e615470a.js"><link rel="prefetch" href="/assets/js/94.0ad7c41c.js"><link rel="prefetch" href="/assets/js/95.0e5ce618.js"><link rel="prefetch" href="/assets/js/96.b59cf9f4.js"><link rel="prefetch" href="/assets/js/97.2a327746.js"><link rel="prefetch" href="/assets/js/98.9c01ec88.js"><link rel="prefetch" href="/assets/js/99.952046bd.js">
    <link rel="stylesheet" href="/assets/css/0.styles.ccac5a78.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="https://github.com/fluidicon.png" alt="独角兕大王" class="logo"> <span class="site-name can-hide">独角兕大王</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/python/" class="nav-link router-link-active">
  Python
</a></div><div class="nav-item"><a href="/rust/" class="nav-link">
  Rust
</a></div><div class="nav-item"><a href="/go/" class="nav-link">
  Go
</a></div><div class="nav-item"><a href="/java/" class="nav-link">
  Java
</a></div><div class="nav-item"><a href="/lua/" class="nav-link">
  Lua
</a></div><div class="nav-item"><a href="/C/" class="nav-link">
  C++
</a></div><div class="nav-item"><a href="https://github.com/wuyuz" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div><div class="nav-item"><a href="https://www.cnblogs.com/double-W/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  cnblogs
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">
  Home
</a></div><div class="nav-item"><a href="/python/" class="nav-link router-link-active">
  Python
</a></div><div class="nav-item"><a href="/rust/" class="nav-link">
  Rust
</a></div><div class="nav-item"><a href="/go/" class="nav-link">
  Go
</a></div><div class="nav-item"><a href="/java/" class="nav-link">
  Java
</a></div><div class="nav-item"><a href="/lua/" class="nav-link">
  Lua
</a></div><div class="nav-item"><a href="/C/" class="nav-link">
  C++
</a></div><div class="nav-item"><a href="https://github.com/wuyuz" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Github
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div><div class="nav-item"><a href="https://www.cnblogs.com/double-W/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  cnblogs
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Python常用模块</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Python基础</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Python进阶</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Django框架</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Flask 框架</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>Python爬虫</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/python/spider/HTTP和HTTPS协议.html" class="sidebar-link">HTTP和HTTPS协议</a></li><li><a href="/python/spider/request模块高级.html" class="sidebar-link">request模块高级</a></li><li><a href="/python/spider/requests相关知识.html" class="sidebar-link">requests相关知识</a></li><li><a href="/python/spider/requests知识进阶.html" class="sidebar-link">requests知识进阶</a></li><li><a href="/python/spider/数据解析.html" class="sidebar-link">数据解析</a></li><li><a href="/python/spider/多任务协程.html" class="sidebar-link">多任务协程爬虫</a></li><li><a href="/python/spider/Scrapy运用与总结.html" class="active sidebar-link">Scrapy运用与总结</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/python/spider/Scrapy运用与总结.html#scrapy运用与总结" class="sidebar-link">Scrapy运用与总结</a></li><li class="sidebar-sub-header"><a href="/python/spider/Scrapy运用与总结.html#第一个scrapy爬虫项目" class="sidebar-link">第一个Scrapy爬虫项目：</a></li><li class="sidebar-sub-header"><a href="/python/spider/Scrapy运用与总结.html#scrapy-的持久化存储" class="sidebar-link">Scrapy 的持久化存储</a></li><li class="sidebar-sub-header"><a href="/python/spider/Scrapy运用与总结.html#scrapy中的中间件的应用" class="sidebar-link">Scrapy中的中间件的应用</a></li><li class="sidebar-sub-header"><a href="/python/spider/Scrapy运用与总结.html#基于crawlspider的全栈数据爬取" class="sidebar-link">基于CrawlSpider的全栈数据爬取</a></li><li class="sidebar-sub-header"><a href="/python/spider/Scrapy运用与总结.html#分布式爬虫" class="sidebar-link">分布式爬虫</a></li><li class="sidebar-sub-header"><a href="/python/spider/Scrapy运用与总结.html#增量式爬虫" class="sidebar-link">增量式爬虫</a></li></ul></li><li><a href="/python/spider/Selenium记录.html" class="sidebar-link">Selenium万能的自动化爬虫</a></li><li><a href="/python/spider/aiohttp使用详细.html" class="sidebar-link">aiohttp使用详细</a></li><li><a href="/python/spider/爬虫面试案例.html" class="sidebar-link">爬虫面试案例</a></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Python设计模式</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h2 id="scrapy运用与总结"><a href="#scrapy运用与总结" class="header-anchor">#</a> Scrapy运用与总结</h2> <h4 id="介绍"><a href="#介绍" class="header-anchor">#</a> 介绍：</h4> <p>​	Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架。 可以应用在包括数据挖掘，信息处理或存储历史数据等一系列的程序中。所谓的框架就是一个已经被集成了各种功能（高性能异步下载，队列，分布式，解析，持久化等）的具有很强通用性的项目模板。对于框架的学习，重点是要学习其框架的特性、各个功能的用法即可。</p> <p><img src="C:%5CUsers%5Cwanglixing%5CDesktop%5C%E7%9F%A5%E8%AF%86%E7%82%B9%E5%A4%8D%E4%B9%A0%5C%E7%88%AC%E8%99%AB%E7%AC%94%E8%AE%B0%5Cassets%5C1567493148727.png" alt="1567493148727"></p> <h4 id="scrapy主要包含了以下几个组件"><a href="#scrapy主要包含了以下几个组件" class="header-anchor">#</a> Scrapy主要包含了以下几个组件：</h4> <ul><li><strong>引擎(Scrapy)</strong>：用来处理整个系统的数据流，触发事务（框架核心）。</li> <li><strong>调度器(Scheduler)</strong>：用来接受引擎发过来的请求, 压入队列中, 并在引擎再次请求的时候返回. 可以想像成一个URL(抓取网页的网址或者说是链接)的优先队列, 它来决定下一个要抓取的网址是什么, 同时去除重复的网址</li> <li><strong>下载器(Downloader)</strong>：用于下载网页内容,并将网页内容返回给蜘蛛(Scrapy下载器是建立在twisted这个高效的异步模型上的)</li> <li><strong>爬虫(Spiders)</strong>：爬虫是主要干活的, 用于从特定的网页中提取自己需要的信息, 即所谓的实体(Item)。用户也可以从中提取出链接,让Scrapy继续抓取下一个页面</li> <li><strong>项目管道(Pipeline)</strong>：负责处理爬虫从网页中抽取的实体，主要的功能是持久化实体、验证实体的有效性、清除不需要的信息。当页面被爬虫解析后，将被发送到项目管道，并经过几个特定的次序处理数据。</li> <li><strong>下载器中间件(Downloader Middlewares)</strong>：位于Scrapy引擎和下载器之间的框架，主要是处理Scrapy引擎与下载器之间的请求及响应。</li> <li><strong>爬虫中间件(Spider Middlewares)</strong>：介于Scrapy引擎和爬虫之间的框架，主要工作是处理蜘蛛的响应输入和请求输出。</li> <li><strong>调度中间件(Scheduler Middlewares)</strong>：介于Scrapy引擎和调度之间的中间件，从Scrapy引擎发送到调度的请求和响应。</li></ul> <h4 id="scrapy运行流程大概如下"><a href="#scrapy运行流程大概如下" class="header-anchor">#</a> Scrapy运行流程大概如下：</h4> <ul><li>引擎从调度器中取出一个链接(URL)用于接下来的抓取</li> <li>引擎把URL封装成一个请求(Request)传给下载器</li> <li>下载器把资源下载下来，并封装成应答包(Response)</li> <li>爬虫解析Response</li> <li>解析出实体（Item）,则交给实体管道进行进一步的处理</li> <li>解析出的是链接（URL）,则把URL交给调度器等待抓取</li></ul> <h4 id="安装scrapy命令"><a href="#安装scrapy命令" class="header-anchor">#</a> 安装Scrapy命令：</h4> <div class="language- extra-class"><pre class="language-text"><code>Linux：
      pip3 install scrapy

Windows：
      a. pip3 install wheel
      b. 下载twisted http://www.lfd.uci.edu/~gohlke/pythonlibs/#twisted
      c. 进入下载目录，执行 pip3 install Twisted‑17.1.0‑cp35‑cp35m‑win_amd64.whl
      d. pip3 install pywin32
      e. pip3 install scrapy
</code></pre></div><h2 id="第一个scrapy爬虫项目"><a href="#第一个scrapy爬虫项目" class="header-anchor">#</a> 第一个Scrapy爬虫项目：</h2> <ul><li><p>进入终端创建项目：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token number">1</span>、cd进一个文件夹中，输入scrapy，查看环境是否搭建完成
<span class="token number">2</span>、创建第一个project：scrapy startproject firstBlood<span class="token punctuation">(</span>项目名<span class="token punctuation">)</span>

创建的目录结构：
    project_name<span class="token operator">/</span>
       scrapy<span class="token punctuation">.</span>cfg  <span class="token comment">#项目的主配置信息。（真正爬虫相关的配置信息在settings.py文件中）</span>
       project_name<span class="token operator">/</span>
           __init__<span class="token punctuation">.</span>py
           items<span class="token punctuation">.</span>py     <span class="token comment">#设置数据存储模板，用于结构化数据，如：Django的Model</span>
           pipelines<span class="token punctuation">.</span>py <span class="token comment">#数据持久化处理模块</span>
           settings<span class="token punctuation">.</span>py  <span class="token comment">#配置文件，如：递归的层数、并发数，延迟下载等</span>
           spiders<span class="token operator">/</span>     <span class="token comment"># 爬虫目录，如：创建文件，编写爬虫解析规则</span>
               __init__<span class="token punctuation">.</span>py
            
<span class="token number">3</span>、在创建爬虫应用程序：（不能用pycharm工具创建py文件，必须cd到项目中，执行下列命令：
   <span class="token operator">&gt;</span>cd project_name（进入项目目录）
   <span class="token operator">&gt;</span>scrapy genspider 应用名称 爬取网页的起始url （例如：scrapy genspider qiubai www<span class="token punctuation">.</span>qiushibaike<span class="token punctuation">.</span>com）<span class="token punctuation">,</span>其实url可以修改在生成后

<span class="token number">4</span>、编写爬虫文件<span class="token punctuation">:</span>在步骤<span class="token number">2</span>执行完毕后，会在项目的spiders中生成一个应用名的py爬虫文件，文件源码如下：
    
<span class="token keyword">import</span> scrapy
<span class="token keyword">class</span> <span class="token class-name">FirstSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment">#这个类型前半部分是我们写的项目名，后面是它拼接的Spider</span>
    name <span class="token operator">=</span> <span class="token string">'first'</span>   <span class="token comment">#应用名称，唯一标识，则spider文件夹中是可以创建多个爬虫文件</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'www.xxx.com'</span><span class="token punctuation">]</span> <span class="token comment">#允许爬取的域名（如果遇到非该域名的url则爬取不到数据），通常不需要，注释</span>
    start_urls <span class="token operator">=</span>  <span class="token punctuation">[</span><span class="token string">'https://www.baidu.com/'</span><span class="token punctuation">,</span><span class="token string">'https://www.sogou.com/'</span><span class="token punctuation">]</span> <span class="token comment">#起始爬取的url，列表中存放的url会被scrapy自动的进行请求发送</span>
	
     <span class="token comment">#访问起始URL并获取结果后的回调函数，该函数的response参数就是向起始的url发送请求后，获取的响应对象.该函数返回值必须为可迭代对象或者NUll </span>
    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>text<span class="token punctuation">)</span> <span class="token comment">#获取字符串类型的响应内容</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">.</span>body<span class="token punctuation">)</span> <span class="token comment">#获取字节类型的相应内容</span>
        <span class="token keyword">pass</span>

<span class="token number">5</span>、设置修改settings<span class="token punctuation">.</span>py配置文件相关配置<span class="token punctuation">:</span>
  修改内容及其结果如下：
	<span class="token number">19</span>行：USER_AGENT <span class="token operator">=</span> <span class="token string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36'</span> <span class="token comment">#伪装请求载体身份</span>

	<span class="token number">22</span>行：ROBOTSTXT_OBEY <span class="token operator">=</span> <span class="token boolean">False</span>  <span class="token comment">#可以忽略或者不遵守robots协议  </span>
    <span class="token number">23</span>行：LOG_LEVEL <span class="token operator">=</span><span class="token string">'ERROR'</span>  <span class="token comment">#设置日志报错等级</span>
    
<span class="token number">6</span>、小试牛刀<span class="token punctuation">,</span>爬取下百度和搜狐的首页：（需要注释掉域名列表，并且要在项目目录下执行）
	 scrapy crawl 爬虫名称 ：该种执行形式会显示执行的日志信息
     scrapy crawl 爬虫名称 <span class="token operator">-</span><span class="token operator">-</span>nolog：该种执行形式不会显示执行的日志信息
     如：\scrapy学习\firstBlood<span class="token operator">&gt;</span>scrapy crawl first

</code></pre></div><ul><li><p>实例：将糗百中的内容和标题进行爬取</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment"># -*- coding: utf-8 -*-</span>
<span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">QiubaiSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'qiubai'</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'https://www.qiushibaike.com/'</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'https://www.qiushibaike.com/'</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#xpath为response中的方法，可以将xpath表达式直接作用于该函数中</span>
        odiv <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//div[@id=&quot;content-left&quot;]/div'</span><span class="token punctuation">)</span>
        content_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span> <span class="token comment">#用于存储解析到的数据</span>
        <span class="token keyword">for</span> div <span class="token keyword">in</span> odiv<span class="token punctuation">:</span>
            <span class="token comment">#xpath函数返回的为列表，列表中存放的数据为Selector类型的数据。我们解析到的内容被封装在了Selector对象中，需要调用extract()函数将解析的内容从Selecor中取出。</span>
            author <span class="token operator">=</span> div<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'.//div[@class=&quot;author clearfix&quot;]/a/h2/text()'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment">#等价于extract_first()</span>
            <span class="token comment">#如果是列表，,extract()函数作用与每个元素</span>
            content<span class="token operator">=</span>div<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'.//div[@class=&quot;content&quot;]/span//text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment">#将解析到的内容封装到字典中</span>
            dic<span class="token operator">=</span><span class="token punctuation">{</span>
                <span class="token string">'作者'</span><span class="token punctuation">:</span>author<span class="token punctuation">,</span>
                <span class="token string">'内容'</span><span class="token punctuation">:</span>content 
            <span class="token punctuation">}</span>
            <span class="token comment">#将数据存储到content_list这个列表中</span>
            content_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>dic<span class="token punctuation">)</span>

        <span class="token keyword">return</span> content_list
</code></pre></div></li></ul></li></ul> <h2 id="scrapy-的持久化存储"><a href="#scrapy-的持久化存储" class="header-anchor">#</a> Scrapy 的持久化存储</h2> <ul><li><h5 id="基于终端指令"><a href="#基于终端指令" class="header-anchor">#</a> 基于终端指令</h5> <ul><li><p>特性: 只可以将parse方法的返回值存到本地磁盘文件中，保证爬虫文件的parse方法中有可迭代类型对象（通常为列表or字典）的返回，该返回值可以通过终端指令的形式写入指定格式的文件中进行持久化操作。</p></li> <li><p>指令：</p> <div class="language-python extra-class"><pre class="language-python"><code>执行输出指定格式进行存储：将爬取到的数据写入不同格式的文件中进行存储，没有txt文件格式
    scrapy crawl 爬虫名称 <span class="token operator">-</span>o xxx<span class="token punctuation">.</span>json
    scrapy crawl 爬虫名称 <span class="token operator">-</span>o xxx<span class="token punctuation">.</span>xml
    scrapy crawl 爬虫名称 <span class="token operator">-</span>o xxx<span class="token punctuation">.</span>csv    
</code></pre></div></li></ul></li> <li><p><strong>基于管道</strong>：主要用于数据解析</p> <p>scrapy框架中已经为我们专门集成好了高效、便捷的持久化操作功能，我们直接使用即可。要想使用scrapy的持久化操作功能，我们首先来认识如下两个文件：</p> <div class="language- extra-class"><pre class="language-text"><code>items.py：数据结构模板文件。定义数据属性。
pipelines.py：管道文件。接收数据（items），进行持久化操作。
</code></pre></div><h5 id="持久化流程"><a href="#持久化流程" class="header-anchor">#</a> 持久化流程：</h5> <div class="language- extra-class"><pre class="language-text"><code>	1.爬虫文件爬取到数据后(parse函数解析的数据），需要将数据封装到items对象中。（item对象就是item.py文件中对应的类的对象）
	2.在item类中定义相应的属性，用来存储我们解析的数据，在parse函数中调用item对象，并赋值
    3.使用yield关键字将items对象提交给pipelines管道进行持久化操作。将item数据提交给管道 
    4.在管道文件中的process_item方法中接收爬虫文件提交过来的item对象，然后编写持久化存储的代码将item对象中存储的数据进行持久化存储
    5.settings.py配置文件中开启管道：在settings中打开ITEM_PIPELINES，LOG_LEVEL = 'ERROR'
LOG_FILE = './log.txt'，以及USER_AGENT
</code></pre></div><ul><li><p>代码演示：将糗百的文字数据存储</p> <div class="language-python extra-class"><pre class="language-python"><code> <span class="token comment">#item.py文件中，对解析完的数据进行封装处理</span>
<span class="token keyword">import</span> scrapy
<span class="token keyword">class</span> <span class="token class-name">FirstbloodItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">#Field可以将其理解成一个万能的数据类型，可以存任意数据类型，Field不能写死，只能用万能的</span>
    author <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    content <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
 <span class="token comment">#parse函数对相应数据先交给item、后交给pipeline</span>
<span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> firstBlood<span class="token punctuation">.</span>items <span class="token keyword">import</span> FirstbloodItem

<span class="token keyword">class</span> <span class="token class-name">SencondSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'sencond'</span>
    <span class="token comment"># allowed_domains = ['www.xxx.com']</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'https://www.qiushibaike.com/text/'</span><span class="token punctuation">]</span>


    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        div_list <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//*[@id=&quot;content-left&quot;]/div'</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> div <span class="token keyword">in</span> div_list<span class="token punctuation">:</span>
            author <span class="token operator">=</span> div<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./div[1]/a[2]/h2/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            content <span class="token operator">=</span> div<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./a/div/span//text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># 每次循环的数据都要实例化一个item类</span>
            item <span class="token operator">=</span> FirstbloodItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment"># 类似于字典，item已经封装好了，将各字段封装成字典</span>
            item<span class="token punctuation">[</span><span class="token string">'author'</span><span class="token punctuation">]</span> <span class="token operator">=</span> author
            item<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>content<span class="token punctuation">)</span>
			<span class="token comment"># 交给管道，一定提交给优先级高的管道类</span>
            <span class="token keyword">yield</span> item

<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
 <span class="token comment">#管道，用于数据的持久化储存</span>
<span class="token keyword">class</span> <span class="token class-name">FirstbloodPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">#设置全局变量，否则无效</span>
    fp <span class="token operator">=</span> <span class="token boolean">None</span>

    <span class="token comment">#重写父类的方法</span>
    <span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'开始爬虫'</span><span class="token punctuation">)</span>
        <span class="token comment"># 只打开一次文件就行了，不用反复打开，开始爬虫时就会执行</span>
        self<span class="token punctuation">.</span>fp <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'qiushibaike.txt'</span><span class="token punctuation">,</span><span class="token string">'w'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>

    <span class="token comment"># 用于接收爬虫文件提交过来的item，然后将其进行任意形式的持久化存储，</span>
    <span class="token comment">#参数item：就是接收到的item对象,一次接受一个item</span>
    <span class="token comment">#该方法每接受一个item就会调用一次</span>
    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        author <span class="token operator">=</span> item<span class="token punctuation">[</span><span class="token string">'author'</span><span class="token punctuation">]</span>
        content <span class="token operator">=</span> item<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>write<span class="token punctuation">(</span>author<span class="token operator">+</span><span class="token string">&quot;:&quot;</span><span class="token operator">+</span>content<span class="token operator">+</span><span class="token string">'\n'</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> item

    <span class="token comment"># 重写父类方法，当爬虫结束后执行</span>
    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'爬虫结束'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
 <span class="token comment"># settings.py文件</span>
ITEM_PIPELINES <span class="token operator">=</span> <span class="token punctuation">{</span>
   <span class="token string">'firstBlood.pipelines.FirstbloodPipeline'</span><span class="token punctuation">:</span> <span class="token number">300</span><span class="token punctuation">,</span> <span class="token comment">#300表示管道优先级，意思是可以开启多个管道</span>
<span class="token punctuation">}</span>
</code></pre></div></li></ul></li> <li><p>将同一份数据持久化到不同的平台中</p> <ul><li><p>分析：</p> <ul><li><p>管道文件中的一个管道类负责数据的一种形式的持久化存储</p></li> <li><p>爬虫文件向管道提交item只会提交给优先级最高的那一个管道类（值越小越大）</p></li> <li><p>在管道类的process_item中的return item表示的时将当前管道接受的 item提交给下一个即将执行的管道类（优先级低次的）</p> <div class="language-mysql extra-class"><pre class="language-text"><code>首先需要创建一个表：
mysql&gt; create database s1 charset 'utf8';
Query OK, 1 row affected (0.01 sec)

mysql&gt; use s1;
mysql&gt; create table qiubai (author varchar(100),content varchar(5000));
Query OK, 0 rows affected (0.03 sec)
mysql&gt; desc qiubai;
+---------+---------------+------+-----+---------+-------+
| Field   | Type          | Null | Key | Default | Extra |
+---------+---------------+------+-----+---------+-------+
| author  | varchar(100)  | YES  |     | NULL    |       |
| content | varchar(5000) | YES  |     | NULL    |       |
+---------+---------------+------+-----+---------+-------+
mysql&gt; commit;
</code></pre></div></li></ul></li> <li><p>代码实现: sencond.py 爬虫文件不需要改变，每次依旧返回item， 主要还是针对管道类return item来实现多管道存储</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> pymysql
<span class="token keyword">from</span> redis <span class="token keyword">import</span> Redis

<span class="token keyword">class</span> <span class="token class-name">FirstbloodPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">#设置全局变量，否则无效</span>
    fp <span class="token operator">=</span> <span class="token boolean">None</span>

    <span class="token comment">#重写父类的方法</span>
    <span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'开始爬虫'</span><span class="token punctuation">)</span>
        <span class="token comment"># 只打开一次文件就行了，不用反复打开，开始爬虫时就会执行</span>
        self<span class="token punctuation">.</span>fp <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'qiushibaike.txt'</span><span class="token punctuation">,</span><span class="token string">'w'</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>

    <span class="token comment"># 用于接收爬虫文件提交过来的item，然后将其进行任意形式的持久化存储，</span>
    <span class="token comment">#参数item：就是接收到的item对象,一次接受一个item</span>
    <span class="token comment">#该方法每接受一个item就会调用一次</span>
    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        author <span class="token operator">=</span> item<span class="token punctuation">[</span><span class="token string">'author'</span><span class="token punctuation">]</span>
        content <span class="token operator">=</span> item<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>write<span class="token punctuation">(</span>author<span class="token operator">+</span><span class="token string">&quot;:&quot;</span><span class="token operator">+</span>content<span class="token operator">+</span><span class="token string">'\n'</span><span class="token punctuation">)</span>

        <span class="token comment"># 注意pipeline类中写了return item，表示会交给紧接这该类的优先级的管道类处理</span>
        <span class="token keyword">return</span> item

    <span class="token comment"># 重写父类方法，当爬虫结束后执行</span>
    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'爬虫结束'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token comment"># 自定义存储类，用于数据存储到mysql中</span>
<span class="token keyword">class</span> <span class="token class-name">MysqlPL</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    conn <span class="token operator">=</span> <span class="token boolean">None</span>   <span class="token comment">#数据库连接</span>
    cursor <span class="token operator">=</span> <span class="token boolean">None</span>  <span class="token comment"># 执行sql语句</span>
    <span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>conn <span class="token operator">=</span> pymysql<span class="token punctuation">.</span>Connect<span class="token punctuation">(</span>host<span class="token operator">=</span><span class="token string">'127.0.0.1'</span><span class="token punctuation">,</span>port<span class="token operator">=</span><span class="token number">3306</span><span class="token punctuation">,</span>user<span class="token operator">=</span><span class="token string">'root'</span><span class="token punctuation">,</span>password<span class="token operator">=</span><span class="token string">'123'</span><span class="token punctuation">,</span>db<span class="token operator">=</span><span class="token string">'s1'</span><span class="token punctuation">,</span>charset<span class="token operator">=</span><span class="token string">'utf8'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>item<span class="token punctuation">,</span>spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        author <span class="token operator">=</span> item<span class="token punctuation">[</span><span class="token string">'author'</span><span class="token punctuation">]</span>
        content <span class="token operator">=</span> item<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span>

        sql <span class="token operator">=</span> <span class="token string">&quot;insert into qiubai values ('%s','%s')&quot;</span><span class="token operator">%</span><span class="token punctuation">(</span>author<span class="token punctuation">,</span>content<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cursor <span class="token operator">=</span> self<span class="token punctuation">.</span>conn<span class="token punctuation">.</span>cursor<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment">#创建游标</span>

        <span class="token keyword">try</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>cursor<span class="token punctuation">.</span>execute<span class="token punctuation">(</span>sql<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>conn<span class="token punctuation">.</span>commit<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span>e<span class="token punctuation">)</span>
            self<span class="token punctuation">.</span>conn<span class="token punctuation">.</span>rollback<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment">#回滚</span>

        <span class="token comment">#仍然返回给下一个管道，当然可以不写</span>
        <span class="token keyword">return</span> item

    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>cursor<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conn<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment">#重点:首先如果你的settings中的ITEM_PIPELINE写了第一种类的优先级最高，但是你在这把那个类删除了，意味着后面的类都拿不到item了</span>
<span class="token keyword">class</span> <span class="token class-name">RedisPL</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    conn <span class="token operator">=</span> <span class="token boolean">None</span>
    <span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>conn <span class="token operator">=</span> Redis<span class="token punctuation">(</span>host<span class="token operator">=</span><span class="token string">'127.0.0.1'</span><span class="token punctuation">,</span>port<span class="token operator">=</span><span class="token number">6379</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>conn<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>item<span class="token punctuation">,</span>spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 注意我们之前说的item是一个类似与字典的数据结构，相对有序字典</span>
        self<span class="token punctuation">.</span>conn<span class="token punctuation">.</span>lpush<span class="token punctuation">(</span><span class="token string">'all_data'</span><span class="token punctuation">,</span>item<span class="token punctuation">)</span>  <span class="token comment">#每次将item添加到 all_data的列表中</span>

        
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
 <span class="token comment">#settings.py文件</span>
ITEM_PIPELINES <span class="token operator">=</span> <span class="token punctuation">{</span>
   <span class="token comment"># 这里的优先级越高，数值越小，也就是说第一个大于第二个优先级</span>
   <span class="token string">'firstBlood.pipelines.FirstbloodPipeline'</span><span class="token punctuation">:</span> <span class="token number">300</span><span class="token punctuation">,</span> <span class="token comment">#300表示管道优先级，意思是可以开启多个管道</span>
   <span class="token string">'firstBlood.pipelines.MysqlPL'</span><span class="token punctuation">:</span><span class="token number">301</span> <span class="token punctuation">,</span> <span class="token comment">#yield item 选择优先级高的管道类</span>
   <span class="token string">'firstBlood.pipelines.RedisPL'</span><span class="token punctuation">:</span><span class="token number">302</span>
<span class="token punctuation">}</span>  <span class="token comment">#同时向三个管道中输入问及那存储</span>
</code></pre></div><ul><li><p>注意：将字典输入到redis的时候报错</p> <div class="language-python extra-class"><pre class="language-python"><code> Invalid <span class="token builtin">input</span> of <span class="token builtin">type</span><span class="token punctuation">:</span> <span class="token string">'FirstbloodItem'</span><span class="token punctuation">.</span> Convert to a byte<span class="token punctuation">,</span> string <span class="token keyword">or</span> number first<span class="token punctuation">.</span>

 <span class="token comment">#解决办法：降低redis版本&gt;&gt;pip install -U redis==2.10.6</span>
</code></pre></div></li></ul></li></ul></li> <li><p>面试题：如果最终需要将爬取到的数据值一份存储到磁盘文件，一份存储到数据库中，则应该如何操作scrapy？</p> <div class="language-python extra-class"><pre class="language-python"><code>管道文件中的代码为

<span class="token comment">#该类为管道类，该类中的process_item方法是用来实现持久化存储操作的。</span>
<span class="token keyword">class</span> <span class="token class-name">DoublekillPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#持久化操作代码 （方式1：写入磁盘文件）</span>
        <span class="token keyword">return</span> item

<span class="token comment">#如果想实现另一种形式的持久化操作，则可以再定制一个管道类：</span>
<span class="token keyword">class</span> <span class="token class-name">DoublekillPipeline_db</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#持久化操作代码 （方式1：写入数据库）</span>
        <span class="token keyword">return</span> item

在settings<span class="token punctuation">.</span>py开启管道操作代码为：

<span class="token comment">#下列结构为字典，字典中的键值表示的是即将被启用执行的管道文件和其执行的优先级。</span>
ITEM_PIPELINES <span class="token operator">=</span> <span class="token punctuation">{</span>
   <span class="token string">'doublekill.pipelines.DoublekillPipeline'</span><span class="token punctuation">:</span> <span class="token number">300</span><span class="token punctuation">,</span>
   <span class="token string">'doublekill.pipelines.DoublekillPipeline_db'</span><span class="token punctuation">:</span> <span class="token number">200</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>

<span class="token comment">#上述代码中，字典中的两组键值分别表示会执行管道文件中对应的两个管道类中的process_item方法，实现两种不同形式的持久化操作</span>
</code></pre></div></li></ul> <h4 id="scrapy手动请求发送"><a href="#scrapy手动请求发送" class="header-anchor">#</a> Scrapy手动请求发送</h4> <p>​	场景：将多个页码对应的数据进行爬取和解析的操作，原始方法：将多个页码的url 放进start_url列表中，但是要是url过多怎么办</p> <ul><li><p>使用场景：爬取多个页码对应的页面源码数据</p></li> <li><p>yield scrapy.Request(new_url, callback=self.parse) 执行回调，形成递归，模板url</p></li> <li><p>实例：将糗事百科所有页码的作者和段子内容数据进行爬取切持久化存储，分析：每一个页面对应一个url，则scrapy工程需要对每一个页码对应的url依次发起请求，然后通过对应的解析方法进行作者和段子内容的解析。</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> firstBlood<span class="token punctuation">.</span>items <span class="token keyword">import</span> FirstbloodItem

<span class="token keyword">class</span> <span class="token class-name">SencondSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'sencond'</span>
    <span class="token comment"># allowed_domains = ['www.xxx.com']</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'https://www.qiushibaike.com/text/'</span><span class="token punctuation">]</span>

    <span class="token comment"># 将多个页码对应的数据进行爬取和解析的操作</span>
    url <span class="token operator">=</span> <span class="token string">'https://www.qiushibaike.com/text/page/%d/'</span>   <span class="token comment">#先制定一个通用的url模板</span>
    <span class="token comment">#page 第一次调用表示的是用来解析第一页对应页面中的段子内容和作者</span>
    pageNum <span class="token operator">=</span> <span class="token number">1</span>
    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        div_list <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//*[@id=&quot;content-left&quot;]/div'</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> div <span class="token keyword">in</span> div_list<span class="token punctuation">:</span>
            author <span class="token operator">=</span> div<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./div[1]/a[2]/h2/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            content <span class="token operator">=</span> div<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./a/div/span//text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># 每次循环的数据都要实例化一个item类</span>
            item <span class="token operator">=</span> FirstbloodItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment"># 类似于字典，item已经封装好了，将各字段封装成字典</span>
            item<span class="token punctuation">[</span><span class="token string">'author'</span><span class="token punctuation">]</span> <span class="token operator">=</span> author
            item<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>content<span class="token punctuation">)</span>

            <span class="token comment">#将item提交给管道</span>
            <span class="token keyword">yield</span> item <span class="token comment">#item一定是提交给了优先级最高的管道类</span>

        <span class="token comment"># 递归条件</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>pageNum <span class="token operator">&lt;=</span> <span class="token number">5</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>pageNum <span class="token operator">+=</span> <span class="token number">1</span>
            new_url <span class="token operator">=</span> self<span class="token punctuation">.</span>url<span class="token operator">%</span>self<span class="token punctuation">.</span>pageNum
            <span class="token comment">#手动请求发送,发起get请求, 使整个函数进行递归，必须要yield，否则响应发送不成功</span>
            <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>new_url<span class="token punctuation">,</span>callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span>
</code></pre></div></li> <li><p>自动重写start_request方法，自动访问网页</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">SencondSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'sencond'</span>
    <span class="token comment"># allowed_domains = ['www.xxx.com']</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'https://www.qiushibaike.com/text/'</span><span class="token punctuation">,</span><span class="token string">'https://www.qiushibaike.com/text/page/2/'</span><span class="token punctuation">,</span><span class="token string">'https://www.qiushibaike.com/text/page/3/'</span><span class="token punctuation">]</span>

    <span class="token comment">#重写start_requests方法循环自动爬取页面</span>
    <span class="token keyword">def</span> <span class="token function">start_requests</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> url <span class="token keyword">in</span> self<span class="token punctuation">.</span>start_urls<span class="token punctuation">:</span>
            <span class="token keyword">yield</span>  scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>url<span class="token punctuation">,</span>callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span>

    pageNum <span class="token operator">=</span> <span class="token number">1</span>
    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        div_list <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//*[@id=&quot;content-left&quot;]/div'</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> div <span class="token keyword">in</span> div_list<span class="token punctuation">:</span>
            author <span class="token operator">=</span> div<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./div[1]/a[2]/h2/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            content <span class="token operator">=</span> div<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./a/div/span//text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># 每次循环的数据都要实例化一个item类</span>
            item <span class="token operator">=</span> FirstbloodItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment"># 类似于字典，item已经封装好了，将各字段封装成字典</span>
            item<span class="token punctuation">[</span><span class="token string">'author'</span><span class="token punctuation">]</span> <span class="token operator">=</span> author
            item<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>content<span class="token punctuation">)</span>

            <span class="token comment">#将item提交给管道</span>
            <span class="token keyword">yield</span> item <span class="token comment">#item一定是提交给了优先级最高的管道类</span>
</code></pre></div></li></ul> <h4 id="scrapy发post请求"><a href="#scrapy发post请求" class="header-anchor">#</a> Scrapy发post请求</h4> <p>​	问题：在之前代码中，我们从来没有手动的对start_urls列表中存储的起始url进行过请求的发送，但是起始url的确是进行了请求的发送，那这是如何实现的呢？</p> <ul><li>解答：其实是因为爬虫文件中的爬虫类继承到了Spider父类中的start_requests（self）这个方法，该方法就可以对start_urls列表中的url发起请求</li></ul> <div class="language-python extra-class"><pre class="language-python"><code>    <span class="token keyword">def</span> <span class="token function">start_requests</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        cls <span class="token operator">=</span> self<span class="token punctuation">.</span>__class__
        <span class="token keyword">if</span> method_is_overridden<span class="token punctuation">(</span>cls<span class="token punctuation">,</span> Spider<span class="token punctuation">,</span> <span class="token string">'make_requests_from_url'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
			<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
            <span class="token keyword">for</span> url <span class="token keyword">in</span> self<span class="token punctuation">.</span>start_urls<span class="token punctuation">:</span>
                <span class="token keyword">yield</span> self<span class="token punctuation">.</span>make_requests_from_url<span class="token punctuation">(</span>url<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> url <span class="token keyword">in</span> self<span class="token punctuation">.</span>start_urls<span class="token punctuation">:</span>
                <span class="token keyword">yield</span> Request<span class="token punctuation">(</span>url<span class="token punctuation">,</span> dont_filter<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">make_requests_from_url</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> url<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">&quot;&quot;&quot; This method is deprecated. &quot;&quot;&quot;</span>
        <span class="token keyword">return</span> Request<span class="token punctuation">(</span>url<span class="token punctuation">,</span> dont_filter<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment">#Request中默认的method=GET</span>
</code></pre></div><p>该方法默认的实现，是对起始的url发起get请求，如果想发起post请求，则需要子类重写该方法。</p> <div class="language-python extra-class"><pre class="language-python"><code> <span class="token comment">#方法： 重写start_requests方法，让其发起post请求</span>
 
<span class="token keyword">def</span> <span class="token function">start_requests</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#请求的url</span>
        post_url <span class="token operator">=</span> <span class="token string">'http://fanyi.baidu.com/sug'</span>
        <span class="token comment"># post请求参数</span>
        formdata <span class="token operator">=</span> <span class="token punctuation">{</span>
            <span class="token string">'kw'</span><span class="token punctuation">:</span> <span class="token string">'wolf'</span><span class="token punctuation">,</span>
        <span class="token punctuation">}</span>
        <span class="token comment"># 发送post请求</span>
        <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>FormRequest<span class="token punctuation">(</span>url<span class="token operator">=</span>post_url<span class="token punctuation">,</span> formdata<span class="token operator">=</span>formdata<span class="token punctuation">,</span> callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span>
</code></pre></div><h4 id="如何基于scrapy进行图片数据的爬取"><a href="#如何基于scrapy进行图片数据的爬取" class="header-anchor">#</a> 如何基于Scrapy进行图片数据的爬取</h4> <ul><li><p>实例：爬取笑话网的图片，url：<a href="http://www.521609.com/daxuemeinv/" target="_blank" rel="noopener noreferrer">http://www.521609.com/daxuemeinv/<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <div class="language-python extra-class"><pre class="language-python"><code>                          <span class="token comment">#pipeline.py文件</span>
<span class="token comment">#原有的，不用</span>
<span class="token comment"># class ImgproPipeline(object):</span>
<span class="token comment">#     def process_item(self, item, spider):</span>
<span class="token comment">#         return item</span>

<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>pipelines<span class="token punctuation">.</span>images <span class="token keyword">import</span> ImagesPipeline
<span class="token keyword">import</span> scrapy

<span class="token comment">#注意这个类名如果更改，用自己的mingz，相应的配置文件也要改变，所以这里我直接使用它原名</span>
<span class="token keyword">class</span> <span class="token class-name">ImgproPipeline</span><span class="token punctuation">(</span>ImagesPipeline<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token comment">#重写继承类的方法,对某一个媒体资源进行请求发送</span>
    <span class="token comment">#item就是接受到的spider提交过来的item</span>
    <span class="token keyword">def</span> <span class="token function">get_media_requests</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> info<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>item<span class="token punctuation">[</span><span class="token string">'src'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>


     <span class="token comment"># 制定媒体数据存储的名称，在settings.py中配置IMAGEs_STORE</span>
    <span class="token keyword">def</span> <span class="token function">file_path</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> response<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> info<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        name <span class="token operator">=</span> request<span class="token punctuation">.</span>url<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'/'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>name<span class="token punctuation">)</span>
        <span class="token keyword">return</span> name

    <span class="token comment"># 在图片储存好后，交给下一个待执行的管道了，return item</span>
    <span class="token keyword">def</span> <span class="token function">item_completed</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> results<span class="token punctuation">,</span> item<span class="token punctuation">,</span> info<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> item
    
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
 <span class="token comment">#items.py</span>
<span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">ImgproItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># define the fields for your item here like:</span>
    src <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">pass</span>

<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
 <span class="token comment">#img.py文件</span>
<span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> imgPro<span class="token punctuation">.</span>items <span class="token keyword">import</span> ImgproItem

<span class="token keyword">class</span> <span class="token class-name">ImgSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'img'</span>
    <span class="token comment"># allowed_domains = ['www.xxx.com']</span>
    <span class="token comment">#分析url的页码是有规律的，从81开始</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://www.521609.com/daxuemeinv/'</span><span class="token punctuation">]</span>

    <span class="token comment">#url模板</span>
    url <span class="token operator">=</span> <span class="token string">'http://www.521609.com/daxuemeinv/list8%d.html'</span>
    pageNum <span class="token operator">=</span> <span class="token number">1</span>
    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        li_list <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//*[@id=&quot;content&quot;]/div[2]/div[2]/ul/li'</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> li <span class="token keyword">in</span> li_list<span class="token punctuation">:</span>
            img_src <span class="token operator">=</span> <span class="token string">'http://www.521609.com'</span><span class="token operator">+</span>li<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./a[1]/img/@src'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment"># scrapy已经为我们建立好了imgpipeline类</span>

            item<span class="token operator">=</span> ImgproItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">'src'</span><span class="token punctuation">]</span> <span class="token operator">=</span> img_src
            <span class="token comment"># 将图片的地址传给管道，当然我们可以自己使用response.body来接受byte类型，然后给item</span>
            <span class="token keyword">yield</span> item

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>pageNum <span class="token operator">&lt;=</span><span class="token number">3</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>pageNum <span class="token operator">+=</span> <span class="token number">1</span>
            new_url <span class="token operator">=</span> self<span class="token punctuation">.</span>url<span class="token operator">%</span>self<span class="token punctuation">.</span>pageNum

            <span class="token keyword">yield</span>  scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>new_url<span class="token punctuation">,</span>callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span>

 <span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
 <span class="token comment">#settings.py文件</span>
ITEM_PIPELINES <span class="token operator">=</span> <span class="token punctuation">{</span>
   <span class="token string">'imgPro.pipelines.ImgproPipeline'</span><span class="token punctuation">:</span> <span class="token number">300</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>

ROBOTSTXT_OBEY <span class="token operator">=</span> <span class="token boolean">False</span>
LOG_LEVEL <span class="token operator">=</span> <span class="token string">'ERROR'</span>
LOG_FILE <span class="token operator">=</span> <span class="token string">'./log.txt'</span>
IMAGES_STORE <span class="token operator">=</span> <span class="token string">'./imgsLib'</span>
</code></pre></div></li> <li><p>原始方法:</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> xiaohua<span class="token punctuation">.</span>items <span class="token keyword">import</span> XiaohuaItem
<span class="token keyword">class</span> <span class="token class-name">XiahuaSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'xiaohua'</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'www.521609.com'</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://www.521609.com/daxuemeinv/'</span><span class="token punctuation">]</span>

    pageNum <span class="token operator">=</span> <span class="token number">1</span>
    url <span class="token operator">=</span> <span class="token string">'http://www.521609.com/daxuemeinv/list8%d.html'</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        li_list <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//div[@class=&quot;index_img list_center&quot;]/ul/li'</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> li <span class="token keyword">in</span> li_list<span class="token punctuation">:</span>
            school <span class="token operator">=</span> li<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./a/img/@alt'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            img_url <span class="token operator">=</span> li<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./a/img/@src'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>

            item <span class="token operator">=</span> XiaohuaItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">'school'</span><span class="token punctuation">]</span> <span class="token operator">=</span> school
            item<span class="token punctuation">[</span><span class="token string">'img_url'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'http://www.521609.com'</span> <span class="token operator">+</span> img_url

            <span class="token keyword">yield</span> item

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>pageNum <span class="token operator">&lt;</span> <span class="token number">10</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>pageNum <span class="token operator">+=</span> <span class="token number">1</span>
            url <span class="token operator">=</span> <span class="token builtin">format</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>url <span class="token operator">%</span> self<span class="token punctuation">.</span>pageNum<span class="token punctuation">)</span>
            <span class="token comment">#print(url)</span>
            <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>url<span class="token operator">=</span>url<span class="token punctuation">,</span>callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span>


<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
 <span class="token comment">#item.py文件</span>
<span class="token keyword">import</span> scrapy


<span class="token keyword">class</span> <span class="token class-name">XiaohuaItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># define the fields for your item here like:</span>
    <span class="token comment"># name = scrapy.Field()</span>
    school<span class="token operator">=</span>scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    img_url<span class="token operator">=</span>scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
 <span class="token comment">#pipeline.py文件</span>
<span class="token keyword">import</span> json
<span class="token keyword">import</span> os
<span class="token keyword">import</span> urllib<span class="token punctuation">.</span>request
<span class="token keyword">class</span> <span class="token class-name">XiaohuaPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp <span class="token operator">=</span> <span class="token boolean">None</span>

    <span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'开始爬虫'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fp <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'./xiaohua.txt'</span><span class="token punctuation">,</span><span class="token string">'w'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">download_img</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>item<span class="token punctuation">)</span><span class="token punctuation">:</span>
        url <span class="token operator">=</span> item<span class="token punctuation">[</span><span class="token string">'img_url'</span><span class="token punctuation">]</span>
        fileName <span class="token operator">=</span> item<span class="token punctuation">[</span><span class="token string">'school'</span><span class="token punctuation">]</span><span class="token operator">+</span><span class="token string">'.jpg'</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span><span class="token string">'./xiaohualib'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            os<span class="token punctuation">.</span>mkdir<span class="token punctuation">(</span><span class="token string">'./xiaohualib'</span><span class="token punctuation">)</span>
        filepath <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'./xiaohualib'</span><span class="token punctuation">,</span>fileName<span class="token punctuation">)</span>
        urllib<span class="token punctuation">.</span>request<span class="token punctuation">.</span>urlretrieve<span class="token punctuation">(</span>url<span class="token punctuation">,</span>filepath<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>fileName<span class="token operator">+</span><span class="token string">&quot;下载成功&quot;</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        obj <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>item<span class="token punctuation">)</span>
        json_str <span class="token operator">=</span> json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>obj<span class="token punctuation">,</span>ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>write<span class="token punctuation">(</span>json_str<span class="token operator">+</span><span class="token string">'\n'</span><span class="token punctuation">)</span>

        <span class="token comment">#下载图片</span>
        self<span class="token punctuation">.</span>download_img<span class="token punctuation">(</span>item<span class="token punctuation">)</span>
        <span class="token keyword">return</span> item

    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'结束爬虫'</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>

配置文件：

USER_AGENT <span class="token operator">=</span> <span class="token string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36'</span>
ROBOTSTXT_OBEY <span class="token operator">=</span> <span class="token boolean">False</span>
CONCURRENT_REQUESTS <span class="token operator">=</span> <span class="token number">100</span>
COOKIES_ENABLED <span class="token operator">=</span> <span class="token boolean">False</span>
LOG_LEVEL <span class="token operator">=</span> <span class="token string">'ERROR'</span>
RETRY_ENABLED <span class="token operator">=</span> <span class="token boolean">False</span>
DOWNLOAD_TIMEOUT <span class="token operator">=</span> <span class="token number">3</span>
DOWNLOAD_DELAY <span class="token operator">=</span> <span class="token number">3</span>
</code></pre></div></li></ul> <h4 id="scrapy实现请求传参"><a href="#scrapy实现请求传参" class="header-anchor">#</a> Scrapy实现请求传参</h4> <ul><li><p>实现深度爬取：爬取多个层级对应的页面数据</p></li> <li><p>使用场景： 爬取的数据没有在同一张页面中，例如: 我们爬取一个电影网站，电影的名称，评分在一级页面，而要爬取的其他电影详情在其二级子页面中。这时我们就需要用到请求传参。</p></li> <li><p>案例展示：爬取<a href="https://www.4567tv.tv/frim/index1.html" target="_blank" rel="noopener noreferrer">https://www.4567tv.tv/frim/index1.html<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>电影网，将一级页面中的电影名称，类型，评分一级二级页面中的上映时间，导演，片长进行爬取。</p> <div class="language-python extra-class"><pre class="language-python"><code> <span class="token comment">#items.py文件</span>
<span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">MovieItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># define the fields for your item here like:</span>
    title <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    desc <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
 <span class="token comment">#movies.py 文件</span>
<span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> movie<span class="token punctuation">.</span>items <span class="token keyword">import</span> MovieItem

<span class="token keyword">class</span> <span class="token class-name">MoviesSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'movies'</span>
    <span class="token comment"># allowed_domains = ['www.xxx.com']</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'https://www.4567tv.tv/frim/index1.html'</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        li_list <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'/html/body/div[1]/div/div/div/div[2]/ul/li'</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> li <span class="token keyword">in</span> li_list<span class="token punctuation">:</span>
            title <span class="token operator">=</span> li<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./div[1]/a/@title'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            detail_url <span class="token operator">=</span><span class="token string">'https://www.4567tv.tv'</span> <span class="token operator">+</span> li<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./div[1]/a/@href'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># 此时我们可以拿到item了，但是我们不能在这就直接item赋值了额，因为我们还要获取详情页的数据</span>
            item <span class="token operator">=</span> MovieItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span> <span class="token operator">=</span> title

            <span class="token comment">#进行请求传参，将item进行传递,因为是将item放在请求中传递，所以叫请求传参,meta参数是一个字典，该字典</span>
            <span class="token comment">#可以传递给callback指定的回调函数</span>
            <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>detail_url<span class="token punctuation">,</span>callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse_detail<span class="token punctuation">,</span>meta<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'item'</span><span class="token punctuation">:</span>item<span class="token punctuation">}</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">parse_detail</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># item接受的就是我们传递过来的item</span>
        item <span class="token operator">=</span> response<span class="token punctuation">.</span>meta<span class="token punctuation">[</span><span class="token string">'item'</span><span class="token punctuation">]</span>
        desc <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'/html/body/div[1]/div/div/div/div[2]/p[5]/span[2]/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
        item<span class="token punctuation">[</span><span class="token string">'desc'</span><span class="token punctuation">]</span> <span class="token operator">=</span> desc
        <span class="token keyword">yield</span> item
        
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
 <span class="token comment">#pipelines.py文件</span>
<span class="token keyword">class</span> <span class="token class-name">MoviePipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>item<span class="token punctuation">)</span>
        <span class="token keyword">return</span> item
    
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
ROBOTSTXT_OBEY <span class="token operator">=</span> <span class="token boolean">False</span>
LOG_LEVEL <span class="token operator">=</span><span class="token string">'ERROR'</span>
 <span class="token comment">#settings.py文件</span>
ITEM_PIPELINES <span class="token operator">=</span> <span class="token punctuation">{</span>
   <span class="token string">'movie.pipelines.MoviePipeline'</span><span class="token punctuation">:</span> <span class="token number">300</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>

ROBOTSTXT_OBEY <span class="token operator">=</span> <span class="token boolean">False</span>
LOG_LEVEL <span class="token operator">=</span><span class="token string">'ERROR'</span>
</code></pre></div><ul><li><p>原始版本代码演示</p> <div class="language-PYTHON extra-class"><pre class="language-python"><code> <span class="token comment"># 爬虫文件中</span>
<span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> moviePro<span class="token punctuation">.</span>items <span class="token keyword">import</span> MovieproItem

<span class="token keyword">class</span> <span class="token class-name">MovieSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'movie'</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'www.id97.com'</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://www.id97.com/'</span><span class="token punctuation">]</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        div_list <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//div[@class=&quot;col-xs-1-5 movie-item&quot;]'</span><span class="token punctuation">)</span>

        <span class="token keyword">for</span> div <span class="token keyword">in</span> div_list<span class="token punctuation">:</span>
            item <span class="token operator">=</span> MovieproItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">]</span> <span class="token operator">=</span> div<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'.//h1/a/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">'score'</span><span class="token punctuation">]</span> <span class="token operator">=</span> div<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'.//h1/em/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment">#xpath(string(.))表示提取当前节点下所有子节点中的数据值（.）表示当前节点</span>
            item<span class="token punctuation">[</span><span class="token string">'kind'</span><span class="token punctuation">]</span> <span class="token operator">=</span> div<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'.//div[@class=&quot;otherinfo&quot;]'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'string(.)'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">'detail_url'</span><span class="token punctuation">]</span> <span class="token operator">=</span> div<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./div/a/@href'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment">#请求二级详情页面，解析二级页面中的相应内容,通过meta参数进行Request的数据传递</span>
            <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>url<span class="token operator">=</span>item<span class="token punctuation">[</span><span class="token string">'detail_url'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse_detail<span class="token punctuation">,</span>meta<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'item'</span><span class="token punctuation">:</span>item<span class="token punctuation">}</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">parse_detail</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#通过response获取item</span>
        item <span class="token operator">=</span> response<span class="token punctuation">.</span>meta<span class="token punctuation">[</span><span class="token string">'item'</span><span class="token punctuation">]</span>
        item<span class="token punctuation">[</span><span class="token string">'actor'</span><span class="token punctuation">]</span> <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//div[@class=&quot;row&quot;]//table/tr[1]/a/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
        item<span class="token punctuation">[</span><span class="token string">'time'</span><span class="token punctuation">]</span> <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//div[@class=&quot;row&quot;]//table/tr[7]/td[2]/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
        item<span class="token punctuation">[</span><span class="token string">'long'</span><span class="token punctuation">]</span> <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//div[@class=&quot;row&quot;]//table/tr[8]/td[2]/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment">#提交item到管道</span>
        <span class="token keyword">yield</span> item

<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
　<span class="token comment">#items文件：</span>
<span class="token keyword">import</span> scrapy

<span class="token keyword">class</span> <span class="token class-name">MovieproItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># define the fields for your item here like:</span>
    name <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    score <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    time <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token builtin">long</span> <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    actor <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    kind <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    detail_url <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
 <span class="token comment">#管道文件：</span>
<span class="token keyword">import</span> json
<span class="token keyword">class</span> <span class="token class-name">MovieproPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'data.txt'</span><span class="token punctuation">,</span><span class="token string">'w'</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        dic <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>item<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>dic<span class="token punctuation">)</span>
        json<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>dic<span class="token punctuation">,</span>self<span class="token punctuation">.</span>fp<span class="token punctuation">,</span>ensure_ascii<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> item
    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>fp<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div></li></ul></li> <li><p>以上案例只能爬取单页，当我们需要爬取多页时，可以使用CrawlSpider,这里我们先使用收到请求多页的方式爬取</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> movie<span class="token punctuation">.</span>items <span class="token keyword">import</span> MovieItem

<span class="token comment">#多页爬取,之后我们会学习CrawlSpider可以全栈爬取</span>
<span class="token keyword">class</span> <span class="token class-name">MoviesSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'movies'</span>
    <span class="token comment"># allowed_domains = ['www.xxx.com']</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'https://www.4567tv.tv/frim/index1.html'</span><span class="token punctuation">]</span>
    url <span class="token operator">=</span> <span class="token string">'https://www.4567tv.tv/frim/index1-%d.html'</span>
    pageNum <span class="token operator">=</span> <span class="token number">1</span>

    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        li_list <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'/html/body/div[1]/div/div/div/div[2]/ul/li'</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> li <span class="token keyword">in</span> li_list<span class="token punctuation">:</span>
            title <span class="token operator">=</span> li<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./div[1]/a/@title'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            detail_url <span class="token operator">=</span><span class="token string">'https://www.4567tv.tv'</span> <span class="token operator">+</span> li<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./div[1]/a/@href'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># 此时我们可以拿到item了，但是我们不能在这就直接item赋值了额，因为我们还要获取详情页的数据</span>
            item <span class="token operator">=</span> MovieItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span> <span class="token operator">=</span> title

            <span class="token comment">#进行请求传参，将item进行传递,因为是将item放在请求中传递，所以叫请求传参,meta参数是一个字典，该字典</span>
            <span class="token comment">#可以传递给callback指定的回调函数</span>
            <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>detail_url<span class="token punctuation">,</span>callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse_detail<span class="token punctuation">,</span>meta<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'item'</span><span class="token punctuation">:</span>item<span class="token punctuation">}</span><span class="token punctuation">)</span>

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>pageNum <span class="token operator">&lt;</span> <span class="token number">5</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>pageNum <span class="token operator">+=</span> <span class="token number">1</span>
            new_url <span class="token operator">=</span> self<span class="token punctuation">.</span>url <span class="token operator">%</span> self<span class="token punctuation">.</span>pageNum

            <span class="token comment"># 递归，对其他页面进行爬取</span>
            <span class="token keyword">yield</span>  scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>new_url<span class="token punctuation">,</span> callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse<span class="token punctuation">)</span>


    <span class="token keyword">def</span> <span class="token function">parse_detail</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># item接受的就是我们传递过来的item</span>
        item <span class="token operator">=</span> response<span class="token punctuation">.</span>meta<span class="token punctuation">[</span><span class="token string">'item'</span><span class="token punctuation">]</span>
        desc <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'/html/body/div[1]/div/div/div/div[2]/p[5]/span[2]/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
        item<span class="token punctuation">[</span><span class="token string">'desc'</span><span class="token punctuation">]</span> <span class="token operator">=</span> desc
        <span class="token keyword">yield</span> item
</code></pre></div></li> <li><p>总结：</p> <div class="language- extra-class"><pre class="language-text"><code>1、在手动请求的时候传递item：yield scrapy.Request(url,callback=,meta={'item':item})
   将meta这个字典传递给callback，在callback中接收meta：item = response.meta['item']
      
</code></pre></div></li></ul> <h2 id="scrapy中的中间件的应用"><a href="#scrapy中的中间件的应用" class="header-anchor">#</a> Scrapy中的中间件的应用</h2> <ul><li><p><strong>爬虫中间件(Spider Middlewares)</strong>：介于Scrapy引擎和爬虫之间的框架，主要工作是处理蜘蛛的响应输入和请求输出。</p></li> <li><p><strong>下载器中间件(Downloader Middlewares)</strong>：位于Scrapy引擎和下载器之间的框架，主要是处理Scrapy引擎与下载器之间的请求及响应。</p> <ul><li><p>作用：批量拦截请求和响应</p> <ul><li>引擎将请求传递给下载器过程中， 下载中间件可以对请求进行一系列处理。比如设置请求的 User-Agent，设置代理等</li> <li>在下载器完成将Response传递给引擎中，下载中间件可以对响应进行一系列处理。比如进行gzip解压等。</li></ul> <p>我们主要使用下载中间件处理请求，一般会对请求设置随机的User-Agent ，设置随机的代理。目的在于防止爬取网站的反爬虫策略。</p></li></ul></li> <li><h5 id="下载中间件的应用"><a href="#下载中间件的应用" class="header-anchor">#</a> 下载中间件的应用：</h5> <ul><li>拦截请求：
<ul><li>UA伪装</li> <li>代理操作</li></ul></li> <li>拦截响应：</li></ul></li> <li><p>打开middlewares.py文件后，可以看见两个类，分别代表着爬虫中间件/下载中间件，这里我们以下载中间件为例</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">MovieDownloaderMiddleware</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Not all methods need to be defined. If a method is not defined,</span>
    <span class="token comment"># scrapy acts as if the downloader middleware does not modify the</span>
    <span class="token comment"># passed objects.</span>

    <span class="token decorator annotation punctuation">@classmethod</span>
    <span class="token keyword">def</span> <span class="token function">from_crawler</span><span class="token punctuation">(</span>cls<span class="token punctuation">,</span> crawler<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># This method is used by Scrapy to create your spiders.</span>
        s <span class="token operator">=</span> cls<span class="token punctuation">(</span><span class="token punctuation">)</span>
        crawler<span class="token punctuation">.</span>signals<span class="token punctuation">.</span>connect<span class="token punctuation">(</span>s<span class="token punctuation">.</span>spider_opened<span class="token punctuation">,</span> signal<span class="token operator">=</span>signals<span class="token punctuation">.</span>spider_opened<span class="token punctuation">)</span>
        <span class="token keyword">return</span> s
    
	<span class="token comment">#拦截正常请求，参数request就是拦截到的请求对象</span>
    <span class="token keyword">def</span> <span class="token function">process_request</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># Called for each request that goes through the downloader</span>
        <span class="token comment"># middleware.</span>

        <span class="token comment"># Must either:</span>
        <span class="token comment"># - return None: continue processing this request</span>
        <span class="token comment"># - or return a Response object</span>
        <span class="token comment"># - or return a Request object</span>
        <span class="token comment"># - or raise IgnoreRequest: process_exception() methods of</span>
        <span class="token comment">#   installed downloader middleware will be called</span>
        <span class="token keyword">return</span> <span class="token boolean">None</span>
	
    <span class="token comment">#拦截异常响应：参数response就是拦截到的响应</span>
    <span class="token keyword">def</span> <span class="token function">process_response</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> response<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># Called with the response returned from the downloader.</span>

        <span class="token comment"># Must either;</span>
        <span class="token comment"># - return a Response object</span>
        <span class="token comment"># - return a Request object</span>
        <span class="token comment"># - or raise IgnoreRequest</span>
        <span class="token keyword">return</span> response
	
    <span class="token comment">#拦截发生异常的请求</span>
    <span class="token keyword">def</span> <span class="token function">process_exception</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> exception<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#拦截到的异常请求然后对其进行修正，然后重新进行请求发送</span>
        <span class="token comment"># Called when a download handler or a process_request()</span>
        <span class="token comment"># (from other downloader middleware) raises an exception.</span>

        <span class="token comment"># Must either:</span>
        <span class="token comment"># - return None: continue processing this exception</span>
        <span class="token comment"># - return a Response object: stops process_exception() chain</span>
        <span class="token comment"># - return a Request object: stops process_exception() chain</span>
        <span class="token keyword">pass</span>
	
    <span class="token keyword">def</span> <span class="token function">spider_opened</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#打印日志</span>
        spider<span class="token punctuation">.</span>logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">'Spider opened: %s'</span> <span class="token operator">%</span> spider<span class="token punctuation">.</span>name<span class="token punctuation">)</span>
</code></pre></div></li> <li><p>（拦截请求）UA伪装和代理池的设置：将所有的请求尽可能多的设定成不同请求载体身份标识（通过UA池）</p> <ul><li><p>我们不是在配置文件中配置了USER_AGENT? 有必要在中间件中再次进行UA伪装,在配置文件中的UA伪装，将所有的请求都使用同一套伪装，而通过中间件，我们可以为每一个请求进行UA伪装。有的网站会检测同一个User_Agent的高频访问，从而禁止。</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> random
<span class="token comment">#可被选用的代理IP</span>
PROXY_http <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">'153.180.102.104:80'</span><span class="token punctuation">,</span>
    <span class="token string">'195.208.131.189:56055'</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>
PROXY_https <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token string">'120.83.49.90:9000'</span><span class="token punctuation">,</span>
    <span class="token string">'95.189.112.214:35508'</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>

<span class="token comment">#UA池</span>
user_agent_list <span class="token operator">=</span> <span class="token punctuation">[</span>
        <span class="token string">&quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 &quot;</span>
        <span class="token string">&quot;(KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1&quot;</span><span class="token punctuation">,</span>
       <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
        <span class="token string">&quot;(KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24&quot;</span><span class="token punctuation">,</span>
        <span class="token string">&quot;Mozilla/5.0 (Windows NT 6.2; WOW64) AppleWebKit/535.24 &quot;</span>
        <span class="token string">&quot;(KHTML, like Gecko) Chrome/19.0.1055.1 Safari/535.24&quot;</span>
<span class="token punctuation">]</span>

<span class="token keyword">class</span> <span class="token class-name">MovieDownloaderMiddleware</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">process_request</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 实现：将拦截到的请求尽可能多的设定成不同的请求载体身份标识</span>
        <span class="token comment"># UA池</span>
        request<span class="token punctuation">.</span>headers<span class="token punctuation">[</span><span class="token string">'User-Agent'</span><span class="token punctuation">]</span> <span class="token operator">=</span> random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>user_agent_list<span class="token punctuation">)</span>

        <span class="token comment">#代理IP池</span>
        <span class="token keyword">if</span> request<span class="token punctuation">.</span>url<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">':'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span><span class="token string">'http'</span><span class="token punctuation">:</span>
            request<span class="token punctuation">.</span>meta<span class="token punctuation">[</span><span class="token string">'proxy'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'http://'</span> <span class="token operator">+</span> random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>PROXY_http<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            request<span class="token punctuation">.</span>meta<span class="token punctuation">[</span><span class="token string">'proxy'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'https://'</span> <span class="token operator">+</span> random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>PROXY_https<span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token boolean">None</span>
    
    <span class="token keyword">def</span> <span class="token function">process_response</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> response<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>

        <span class="token keyword">return</span> response

    <span class="token keyword">def</span> <span class="token function">process_exception</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> exception<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 做相关修正操作，如有些网站请求失败后会返回错误页面，也就是说可以访问但是返回的页面是错误的，这时候我们就可以进行修正</span>
        <span class="token comment"># 代理IP池</span>
        <span class="token keyword">if</span> request<span class="token punctuation">.</span>url<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">':'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token string">'http'</span><span class="token punctuation">:</span>
            request<span class="token punctuation">.</span>meta<span class="token punctuation">[</span><span class="token string">'proxy'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'http://'</span> <span class="token operator">+</span> random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>PROXY_http<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            request<span class="token punctuation">.</span>meta<span class="token punctuation">[</span><span class="token string">'proxy'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'https://'</span> <span class="token operator">+</span> random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>PROXY_https<span class="token punctuation">)</span>

        <span class="token comment">#重新发送，将修正之后的请求进行重新发送</span>
        <span class="token keyword">return</span> request

    <span class="token keyword">def</span> <span class="token function">spider_opened</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        spider<span class="token punctuation">.</span>logger<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">'Spider opened: %s'</span> <span class="token operator">%</span> spider<span class="token punctuation">.</span>name<span class="token punctuation">)</span>
</code></pre></div></li></ul></li> <li><p>（拦截响应）：篡改响应数据或者直接替换响应对象，对返回的响应数据进行判定是否是我们想要的</p> <ul><li><p>实例：爬取网易新闻的国内、国际、军事、航空、无人机板块下的新闻数据 url：<a href="https://news.163.com/" target="_blank" rel="noopener noreferrer">https://news.163.com/<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p></li> <li><p>分析：当点击国内超链进入国内对应的页面时，会发现当前页面展示的新闻数据是被动态加载出来的，如果直接通过程序对url进行请求，是获取不到动态加载出的新闻数据的。则就需要我们使用selenium实例化一个浏览器对象，在该对象中进行url的请求，获取动态加载的新闻数据。</p> <div class="language-python extra-class"><pre class="language-python"><code> <span class="token comment">#items.py文件</span>
<span class="token keyword">import</span> scrapy
<span class="token keyword">class</span> <span class="token class-name">WangyiproItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># define the fields for your item here like:</span>
    title <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    content <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
 <span class="token comment">#pipelines.py文件</span>
<span class="token keyword">class</span> <span class="token class-name">WangyiproPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>item<span class="token punctuation">)</span>
        <span class="token keyword">return</span> item
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
 <span class="token comment">#middlewares.py文件中的下载中间件</span>
<span class="token keyword">from</span> scrapy <span class="token keyword">import</span> signals
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>http <span class="token keyword">import</span> HtmlResponse
<span class="token keyword">import</span> time
<span class="token keyword">class</span> <span class="token class-name">WangyiproDownloaderMiddleware</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token keyword">def</span> <span class="token function">process_request</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token boolean">None</span>

    <span class="token comment">#进行响应对象进行拦截,这里的spider就是爬虫文件爬虫类实例化的对象，也就是WangyiSpider类的对象，我们</span>
    <span class="token comment"># 可以通过spider点出类的属性</span>
    <span class="token keyword">def</span> <span class="token function">process_response</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> response<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment">#1、将所有的响应中的那五个不满足要求的response进行截获，先不return它，进行修正后再返回，</span>
        <span class="token comment">#因为这五个response（模板）是动态加载的，也就是说我们拿到的页面不是先要的</span>
            <span class="token comment"># 1、每个响应对象对应唯一一个请求对象</span>
            <span class="token comment"># 2、如果我们可以定位到五个响应对象的请求对象后，就可以通过该请求对象定位到指定的响应对象</span>
            <span class="token comment"># 3、可以通过五个板块的url定位请求对象</span>
            <span class="token comment"># 总结： url --&gt; request --&gt; response</span>


        <span class="token comment">#2、将找到的五个不满足需求的响应对象进行修正</span>
        <span class="token comment">#spider.five_model_urls : 通过spider点出五个模块对应的url</span>
        bro <span class="token operator">=</span> spider<span class="token punctuation">.</span>bro
        <span class="token keyword">if</span> request<span class="token punctuation">.</span>url <span class="token keyword">in</span> spider<span class="token punctuation">.</span>five_model_urls<span class="token punctuation">:</span>
            <span class="token comment"># 如果if条件成立则该response就是五个板块对应的响应对象</span>
            <span class="token comment"># 这里的response就是HtmlResponse类对象</span>
            bro<span class="token punctuation">.</span>get<span class="token punctuation">(</span>request<span class="token punctuation">.</span>url<span class="token punctuation">)</span>
            time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
            page_text <span class="token operator">=</span> bro<span class="token punctuation">.</span>page_source <span class="token comment"># 包含了动态加载</span>
            new_response <span class="token operator">=</span> HtmlResponse<span class="token punctuation">(</span>
                url<span class="token operator">=</span>request<span class="token punctuation">.</span>url<span class="token punctuation">,</span>  <span class="token comment"># 响应对象对应的请求对象</span>
                body<span class="token operator">=</span>page_text<span class="token punctuation">,</span>  <span class="token comment">#将selenums 获得的页面数据传入</span>
                encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">,</span>
                request<span class="token operator">=</span>request  <span class="token comment">#五个模板对应的请求对象</span>
            <span class="token punctuation">)</span>

            <span class="token comment"># 返回新的响应对象，包含着动态加载的新闻数据</span>
            <span class="token keyword">return</span> new_response
        <span class="token keyword">return</span> response
    
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
 <span class="token comment">#爬虫文件，wangyi.py文件</span>
<span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> selenium <span class="token keyword">import</span> webdriver
<span class="token keyword">from</span> wangyiPro<span class="token punctuation">.</span>items <span class="token keyword">import</span> WangyiproItem

<span class="token keyword">class</span> <span class="token class-name">WangyiSpider</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'wangyi'</span>
    <span class="token comment"># allowed_domains = ['wwww.xxx.com']</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'https://news.163.com/'</span><span class="token punctuation">]</span>
    five_model_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token comment"># 创建浏览器对象</span>
    bro <span class="token operator">=</span> webdriver<span class="token punctuation">.</span>Chrome<span class="token punctuation">(</span>executable_path<span class="token operator">=</span><span class="token string">r'D:\21期\爬虫 + 数据分析\tools\chromedriver.exe'</span><span class="token punctuation">)</span>

    <span class="token comment"># 用来解析五个板块对应的url，然后对其进行手动发送发送</span>
    <span class="token keyword">def</span> <span class="token function">parse</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 找出所需模块对应的li标签索引</span>
        model_index <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">,</span><span class="token number">7</span><span class="token punctuation">,</span><span class="token number">8</span><span class="token punctuation">]</span>
        li_list <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//*[@id=&quot;index2016_wrap&quot;]/div[1]/div[2]/div[2]/div[2]/div[2]/div/ul/li'</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> index <span class="token keyword">in</span> model_index<span class="token punctuation">:</span>
            <span class="token comment"># 五个板块的li标签,取出url</span>
            li <span class="token operator">=</span> li_list<span class="token punctuation">[</span>index<span class="token punctuation">]</span>
            model_url <span class="token operator">=</span> li<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./a/@href'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>

            self<span class="token punctuation">.</span>five_model_urls<span class="token punctuation">.</span>append<span class="token punctuation">(</span>model_url<span class="token punctuation">)</span>
            <span class="token comment"># 对每一个板块的url进行手动请求发送</span>
            <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>model_url<span class="token punctuation">,</span>callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse_model<span class="token punctuation">)</span>

    <span class="token comment"># 解析每个板块页面中的新闻标题和新闻详情页的url</span>
    <span class="token comment"># 问题：response中并没有包含每个板块中动态加载出的新闻数据，也就是说这个response是不满足需求的响应</span>
    <span class="token comment"># 解决： 在中间件中，对不满足要求的response进行重新修正或重新加载</span>
    <span class="token keyword">def</span> <span class="token function">parse_model</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 通过中间件中使用selenium处理后每个板块已经获得了动态加载的页面数据后</span>
        div_list <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'/html/body/div/div[3]/div[4]/div[1]/div/div/ul/li/div/div'</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> div <span class="token keyword">in</span> div_list<span class="token punctuation">:</span>
            title <span class="token operator">=</span> div<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./div/div[1]/h3/a/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            detail_url <span class="token operator">=</span> div<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./div/div[1]/h3/a/@href'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>

            item <span class="token operator">=</span> WangyiproItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span> <span class="token operator">=</span> title

            <span class="token comment"># 对详情页发起请求解析出新闻内容,再定义一个回调函数提取新闻内容,将item传递给下一个需要的解析函数</span>
            <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>detail_url<span class="token punctuation">,</span>callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parse_new_content<span class="token punctuation">,</span>meta<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'item'</span><span class="token punctuation">:</span>item<span class="token punctuation">}</span><span class="token punctuation">)</span>


    <span class="token comment">#解析新闻内容</span>
    <span class="token keyword">def</span> <span class="token function">parse_new_content</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        content <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//*[@id=&quot;endText&quot;]//text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>
        content <span class="token operator">=</span> <span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>content<span class="token punctuation">)</span>

        item <span class="token operator">=</span> response<span class="token punctuation">.</span>meta<span class="token punctuation">[</span><span class="token string">'item'</span><span class="token punctuation">]</span>
        
        item<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span> <span class="token operator">=</span> content

        <span class="token keyword">yield</span> item

    <span class="token comment">#重写父类的关闭函数，所有操作的最后执行</span>
    <span class="token keyword">def</span> <span class="token function">closed</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>bro<span class="token punctuation">.</span>quit<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
 <span class="token comment"># settings.py文件</span>
DOWNLOADER_MIDDLEWARES <span class="token operator">=</span> <span class="token punctuation">{</span>
   <span class="token string">'wangyiPro.middlewares.WangyiproDownloaderMiddleware'</span><span class="token punctuation">:</span> <span class="token number">543</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>
ITEM_PIPELINES <span class="token operator">=</span> <span class="token punctuation">{</span>
   <span class="token string">'wangyiPro.pipelines.WangyiproPipeline'</span><span class="token punctuation">:</span> <span class="token number">300</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>

USER_AGENT <span class="token operator">=</span> <span class="token string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.132 Safari/537.36'</span>
ROBOTSTXT_OBEY <span class="token operator">=</span> <span class="token boolean">False</span>
LOG_LEVEL <span class="token operator">=</span> <span class="token string">'ERROR'</span>
</code></pre></div></li></ul></li> <li><p>selenium在scrapy中的应用</p> <ul><li>实例化浏览器对象： 写在爬虫类的构造方法中</li> <li>关闭浏览器：爬虫类中的closed(self,spider) 关闭浏览器</li> <li>在中间件中执行浏览器自动化操作</li></ul></li></ul> <h4 id="百度ai识别新闻关键字"><a href="#百度ai识别新闻关键字" class="header-anchor">#</a> 百度AI识别新闻关键字</h4> <ul><li><p>需求：爬取网易新闻的国内，国际，军事，航空，无人机五个板块下的新闻标题和新闻内容，然后基于百度AI将新闻类型和关键字进行提取，然后将其四个字段写入mysql数据库进行存储！</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> aip <span class="token keyword">import</span> AipNlp  <span class="token comment">#数据上列中已经获取，只需要修改pipeline文件，注意要修改settings中的pipelines文件。</span>
<span class="token comment">#pip install baidu-aip</span>
<span class="token keyword">import</span> pymysql
<span class="token keyword">import</span> time

APP_ID <span class="token operator">=</span> <span class="token string">'17170467'</span>
API_KEY <span class="token operator">=</span> <span class="token string">'I9gTHCwucpgxwPUjepnLrpsG'</span>
SECRET_KEY <span class="token operator">=</span> <span class="token string">'7BouOaHfzde2rv7XD7QPWl40gRB0j7GE'</span>
<span class="token keyword">class</span> <span class="token class-name">MysqlPL</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    client <span class="token operator">=</span> AipNlp<span class="token punctuation">(</span>APP_ID<span class="token punctuation">,</span> API_KEY<span class="token punctuation">,</span> SECRET_KEY<span class="token punctuation">)</span>
    conn <span class="token operator">=</span> <span class="token boolean">None</span>
    cursor <span class="token operator">=</span> <span class="token boolean">None</span>

    <span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 提前在数据库中创建news数据库和new表，包含四个字段</span>
        self<span class="token punctuation">.</span>conn <span class="token operator">=</span> pymysql<span class="token punctuation">.</span>Connect<span class="token punctuation">(</span>host<span class="token operator">=</span><span class="token string">'127.0.0.1'</span><span class="token punctuation">,</span> port<span class="token operator">=</span><span class="token number">3306</span><span class="token punctuation">,</span> user<span class="token operator">=</span><span class="token string">&quot;root&quot;</span><span class="token punctuation">,</span> password<span class="token operator">=</span><span class="token string">'123'</span><span class="token punctuation">,</span> db<span class="token operator">=</span><span class="token string">'news'</span><span class="token punctuation">,</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        title <span class="token operator">=</span> item<span class="token punctuation">[</span><span class="token string">&quot;title&quot;</span><span class="token punctuation">]</span>
        content <span class="token operator">=</span> item<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span>
        tag <span class="token operator">=</span> self<span class="token punctuation">.</span>client<span class="token punctuation">.</span>keyword<span class="token punctuation">(</span>title<span class="token punctuation">,</span>content<span class="token punctuation">)</span>  <span class="token comment"># 标签</span>
        first_tag <span class="token operator">=</span> tag<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'items'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'tag'</span><span class="token punctuation">)</span>

        time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
        types <span class="token operator">=</span> self<span class="token punctuation">.</span>client<span class="token punctuation">.</span>topic<span class="token punctuation">(</span>title<span class="token punctuation">,</span>content<span class="token punctuation">)</span>  <span class="token comment"># 类型</span>
        content_type <span class="token operator">=</span> types<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'item'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'lv1_tag_list'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'tag'</span><span class="token punctuation">)</span>
        sql <span class="token operator">=</span> <span class="token string">'insert into new values (&quot;%s&quot;,&quot;%s&quot;,&quot;%s&quot;,&quot;%s&quot;)'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>title<span class="token punctuation">,</span> content<span class="token punctuation">,</span> content_type<span class="token punctuation">,</span> first_tag<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cursor <span class="token operator">=</span> self<span class="token punctuation">.</span>conn<span class="token punctuation">.</span>cursor<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">try</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>cursor<span class="token punctuation">.</span>execute<span class="token punctuation">(</span>sql<span class="token punctuation">)</span>
        <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>conn<span class="token punctuation">.</span>rollback<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">close_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>cursor<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conn<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div></li></ul> <h2 id="基于crawlspider的全栈数据爬取"><a href="#基于crawlspider的全栈数据爬取" class="header-anchor">#</a> 基于CrawlSpider的全栈数据爬取</h2> <p>提问：如果想要通过爬虫程序去爬取”糗百“全站数据新闻数据的话，有几种实现方法？</p> <p>方法一：基于Scrapy框架中的Spider的递归爬取进行实现（Request模块递归回调parse方法）。</p> <p>方法二：基于CrawlSpider的自动爬取进行实现（更加简洁和高效）。</p> <ul><li><p>**CrawlSpider介绍：**CrawlSpider其实是Spider的一个子类，除了继承到Spider的特性和功能外，还派生除了其自己独有的更加强大的特性和功能。其中最显著的功能就是”LinkExtractors链接提取器“、” Rule : 规则解析器“。Spider是所有爬虫的基类，其设计原则只是为了爬取start_url列表中网页，而从爬取到的网页中提取出的url进行继续的爬取工作使用CrawlSpider更合适。</p></li> <li><p>使用流程：</p> <ul><li><p>创建一个基于CrawlSpider的爬虫文件：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token number">1</span><span class="token punctuation">.</span>创建scrapy工程：scrapy startproject projectName
<span class="token number">2</span><span class="token punctuation">.</span>创建爬虫文件：scrapy genspider <span class="token operator">-</span>t crawl spiderName www<span class="token punctuation">.</span>xxx<span class="token punctuation">.</span>com
　　　　<span class="token operator">-</span><span class="token operator">-</span>此指令对比以前的指令多了 <span class="token string">&quot;-t crawl&quot;</span>，表示创建的爬虫文件是基于CrawlSpider这个类的，而不再是Spider这个基类。

<span class="token number">3</span><span class="token punctuation">.</span>观察生成的爬虫文件
<span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>linkextractors <span class="token keyword">import</span> LinkExtractor <span class="token comment">#连接提取器</span>
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>spiders <span class="token keyword">import</span> CrawlSpider<span class="token punctuation">,</span> Rule  <span class="token comment">#规则解析器</span>

<span class="token keyword">class</span> <span class="token class-name">SunSpider</span><span class="token punctuation">(</span>CrawlSpider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'sun'</span>
    allowed_domains <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'www.xxx.com'</span><span class="token punctuation">]</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://www.xxx.com/'</span><span class="token punctuation">]</span>
	link <span class="token operator">=</span> LinkExtractor<span class="token punctuation">(</span>allow<span class="token operator">=</span><span class="token string">r'Items/'</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    rules <span class="token operator">=</span> <span class="token punctuation">(</span>
        <span class="token comment"># 实例化一个Rule（规则解析器）的对象</span>
        Rule<span class="token punctuation">(</span>link<span class="token punctuation">,</span> callback<span class="token operator">=</span><span class="token string">'parse_item'</span><span class="token punctuation">,</span> follow<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">parse_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        item <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token punctuation">}</span>
        <span class="token comment">#item['domain_id'] = response.xpath('//input[@id=&quot;sid&quot;]/@value').get()</span>
        <span class="token comment">#item['name'] = response.xpath('//div[@id=&quot;name&quot;]').get()</span>
        <span class="token comment">#item['description'] = response.xpath('//div[@id=&quot;description&quot;]').get()</span>
        <span class="token keyword">return</span> item
</code></pre></div></li> <li><p>构造连接提取器和规则解析器：CrawlSpider类和Spider类的最大不同是CrawlSpider多了一个rules属性，其作用是定义”提取动作“。在rules中可以包含一个或多个Rule对象，在Rule对象中包含了LinkExtractor对象</p> <p><strong>连接提取器</strong>：可以根据指定的规则进行指定连接的提取。</p> <div class="language-python extra-class"><pre class="language-python"><code>LinkExtractor：顾名思义，链接提取器。
LinkExtractor<span class="token punctuation">(</span>
　　　　　　　   allow<span class="token operator">=</span><span class="token string">r'Items/'</span>，<span class="token comment">#满足括号中“正则表达式”的值会被提取，如果为空则全部匹配。</span>
　　　　　　　　 deny<span class="token operator">=</span>xxx<span class="token punctuation">,</span>  <span class="token comment">#满足正则表达式的则不会被提取。</span>

　　　　　　　　 restrict_xpaths<span class="token operator">=</span>xxx<span class="token punctuation">,</span> <span class="token comment"># 满足xpath表达式的值会被提取</span>

　　　　　　　　 restrict_css<span class="token operator">=</span>xxx<span class="token punctuation">,</span> <span class="token comment"># 满足css表达式的值会被提取</span>

　　　　　　　　 deny_domains<span class="token operator">=</span>xxx<span class="token punctuation">,</span> <span class="token comment"># 不会被提取的链接的domains。　</span>
　　  <span class="token punctuation">)</span>
</code></pre></div><p>规则解析器：根据链接提取器中提取到的链接，根据指定规则提取解析器链接网页中的内容。</p> <div class="language-python extra-class"><pre class="language-python"><code> Rule<span class="token punctuation">(</span>LinkExtractor<span class="token punctuation">(</span>allow<span class="token operator">=</span><span class="token string">r'Items/'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> callback<span class="token operator">=</span><span class="token string">'parse_item'</span><span class="token punctuation">,</span> follow<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
 参数介绍：
　　　参数<span class="token number">1</span>：指定链接提取器
　　　参数<span class="token number">2</span>：指定规则解析器解析数据的规则（回调函数）
　　　参数<span class="token number">3</span>：是否将链接提取器继续作用到链接提取器提取出的链接网页中。当callback为<span class="token boolean">None</span><span class="token punctuation">,</span>参数<span class="token number">3</span>的默认值为true。
</code></pre></div><p>rules=( ): 指定不同规则解析器。一个Rule对象表示一种提取规则</p></li></ul></li> <li><h5 id="crawlspider整体爬取流程"><a href="#crawlspider整体爬取流程" class="header-anchor">#</a> CrawlSpider整体爬取流程</h5> <ul><li><p>爬虫文件首先根据起始url，获取该url的网页内容a</p></li> <li><p>链接提取器会根据指定提取规则将步骤a中网页内容中的链接进行提取</p></li> <li><p>规则解析器会根据指定解析规则将链接提取器中提取到的链接中的网页内容根据指定的规则进行解析</p></li> <li><p>将解析数据封装到item中，然后提交给管道进行持久化存储</p> <p>案例演示：爬取阳光网投诉信息：url： <a href="http://wz.sun0769.com/index.php/question/questionType?type=4&amp;page=" target="_blank" rel="noopener noreferrer">http://wz.sun0769.com/index.php/question/questionType?type=4&amp;page=<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p>解析出每一页的页码url: follow=True 将连接提取器 继续作用到 连接提取器提取到的页码连接所对应的页面中</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>linkextractors <span class="token keyword">import</span> LinkExtractor
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>spiders <span class="token keyword">import</span> CrawlSpider<span class="token punctuation">,</span> Rule

<span class="token keyword">class</span> <span class="token class-name">SunSpider</span><span class="token punctuation">(</span>CrawlSpider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'sun'</span>
    <span class="token comment"># allowed_domains = ['www.xxx.com']</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://wz.sun0769.com/index.php/question/questionType?type=4&amp;page='</span><span class="token punctuation">]</span>

    <span class="token comment">#连接提取器：http://wz.sun0769.com/index.php/question/report?page=，但是这个规则写的时候太多符号需要转义，所以我们想简化哈</span>
    <span class="token comment">#简化版本：r'report\?page=\d+', 即提取规则，allow表示提取规则</span>
    link <span class="token operator">=</span> LinkExtractor<span class="token punctuation">(</span>allow<span class="token operator">=</span><span class="token string">r'type=4&amp;page=\d+'</span><span class="token punctuation">)</span>

    <span class="token comment">#规则解析器</span>
    <span class="token comment">#作用：获取连接提取器取到的连接，然后对其进行请求发送，根据指定规则对请求到的页面源码数据进行数据解析</span>
    rules <span class="token operator">=</span> <span class="token punctuation">(</span>
        <span class="token comment">#实例化一个Rule对象</span>
        Rule<span class="token punctuation">(</span>link<span class="token punctuation">,</span> callback<span class="token operator">=</span><span class="token string">'parse_item'</span><span class="token punctuation">,</span> follow<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">parse_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>response<span class="token punctuation">)</span>

<span class="token comment">#结果：</span>
<span class="token operator">&lt;</span><span class="token number">200</span> http<span class="token punctuation">:</span><span class="token operator">//</span>wz<span class="token punctuation">.</span>sun0769<span class="token punctuation">.</span>com<span class="token operator">/</span>index<span class="token punctuation">.</span>php<span class="token operator">/</span>question<span class="token operator">/</span>questionType?<span class="token builtin">type</span><span class="token operator">=</span><span class="token number">4</span><span class="token operator">&amp;</span>page<span class="token operator">=</span><span class="token number">111630</span><span class="token operator">&gt;</span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>

<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
获得更多数据

<span class="token keyword">class</span> <span class="token class-name">SunSpider</span><span class="token punctuation">(</span>CrawlSpider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'sun'</span>
    <span class="token comment"># allowed_domains = ['www.xxx.com']</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://wz.sun0769.com/index.php/question/questionType?type=4&amp;page='</span><span class="token punctuation">]</span>

    <span class="token comment">#连接提取器：http://wz.sun0769.com/index.php/question/report?page=，但是这个规则写的时候太多符号需要转义，所以我们想简化哈</span>
    <span class="token comment">#简化版本：r'report\?page=\d+', 即提取规则</span>
    link <span class="token operator">=</span> LinkExtractor<span class="token punctuation">(</span>allow<span class="token operator">=</span><span class="token string">r'type=4&amp;page=\d+'</span><span class="token punctuation">)</span>

    <span class="token comment">#规则解析器</span>
    <span class="token comment">#作用：获取连接提取器取到的连接，然后对其进行请求发送，根据指定规则对请求到的页面源码数据进行数据解析</span>
    rules <span class="token operator">=</span> <span class="token punctuation">(</span>
        <span class="token comment">#实例化一个Rule对象, 这里的follow如果是False，那么只加载起始页的下方的页码连接，如果是True则可以获取每一页的下方的页码url</span>
        <span class="token comment">#且可自动去重，也就是说所有的页码都会获取到</span>
        Rule<span class="token punctuation">(</span>link<span class="token punctuation">,</span> callback<span class="token operator">=</span><span class="token string">'parse_item'</span><span class="token punctuation">,</span> follow<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">parse_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        tr_list <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//*[@id=&quot;morelist&quot;]/div/table[2]//tr/td/table//tr'</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> tr <span class="token keyword">in</span> tr_list<span class="token punctuation">:</span>
            title <span class="token operator">=</span> tr<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./td[2]/a[2]/@title'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            status <span class="token operator">=</span> tr<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./td[3]/span/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span>title<span class="token punctuation">,</span> status<span class="token punctuation">)</span>
</code></pre></div></li></ul></li></ul> <h4 id="基于crawlspider深度爬取"><a href="#基于crawlspider深度爬取" class="header-anchor">#</a> 基于CrawlSpider深度爬取</h4> <ul><li><p>深度爬取：就是爬取多层级页面数据，有些数据爬取的时候不能像之前通过scrapy.Request()函数通过定制元信息meta，进行请求传参，因为这里我们使用的使Rule()规则解析器，所以我们不能进行深度爬取，将一组数据保存在一个item中，这里我们可以使用多个item包装数据，最后通过一个唯一码进行绑定（编号），最好存入数据库。</p> <div class="language-python extra-class"><pre class="language-python"><code> <span class="token comment">#item.py文件</span>
<span class="token keyword">import</span> scrapy
<span class="token comment">#创建两个item类</span>
<span class="token keyword">class</span> <span class="token class-name">SunproItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
    content <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    num <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">class</span> <span class="token class-name">SunproItem_second</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
    title <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    status <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
    num <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
  
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
 <span class="token comment"># pipelines.py文件</span>
<span class="token keyword">class</span> <span class="token class-name">SunproPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> item<span class="token punctuation">.</span>__class__<span class="token punctuation">.</span>__name__ <span class="token operator">==</span> <span class="token string">'SunproItem'</span><span class="token punctuation">:</span>
            content <span class="token operator">=</span> item<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span>
            <span class="token comment"># 执行sql语句，但是发现不能同时存入content以及对应的title、status，我们可以用num标识</span>
            <span class="token comment">#我们通过编号进行唯一码标识</span>
            num <span class="token operator">=</span> item<span class="token punctuation">[</span><span class="token string">'num'</span><span class="token punctuation">]</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span>content<span class="token punctuation">,</span>num<span class="token punctuation">)</span>

        <span class="token keyword">else</span><span class="token punctuation">:</span>
            title <span class="token operator">=</span> item<span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span>
            status <span class="token operator">=</span> item<span class="token punctuation">[</span><span class="token string">'status'</span><span class="token punctuation">]</span>
            num <span class="token operator">=</span> item<span class="token punctuation">[</span><span class="token string">'num'</span><span class="token punctuation">]</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span>num<span class="token punctuation">,</span>title<span class="token punctuation">)</span>

        <span class="token keyword">return</span> item

<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
 <span class="token comment">#sun.py文件</span>
<span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>linkextractors <span class="token keyword">import</span> LinkExtractor
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>spiders <span class="token keyword">import</span> CrawlSpider<span class="token punctuation">,</span> Rule

<span class="token keyword">from</span> sunPro<span class="token punctuation">.</span>items <span class="token keyword">import</span> SunproItem<span class="token punctuation">,</span>SunproItem_second

<span class="token comment">#实现深度爬取</span>
<span class="token keyword">class</span> <span class="token class-name">SunSpider</span><span class="token punctuation">(</span>CrawlSpider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'sun'</span>
    <span class="token comment"># allowed_domains = ['www.xxx.com']</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://wz.sun0769.com/index.php/question/questionType?type=4&amp;page='</span><span class="token punctuation">]</span>

    <span class="token comment">#连接提取器：http://wz.sun0769.com/index.php/question/report?page=，但是这个规则写的时候太多符号需要转义，所以我们想简化哈</span>
    <span class="token comment">#简化版本：r'report\?page=\d+', 即提取规则</span>
    link <span class="token operator">=</span> LinkExtractor<span class="token punctuation">(</span>allow<span class="token operator">=</span><span class="token string">r'type=4&amp;page=\d+'</span><span class="token punctuation">)</span>   <span class="token comment"># 提取页码连接</span>

    <span class="token comment">#详情页：http://wz.sun0769.com/html/question/201909/427019.shtml</span>
    <span class="token comment">#简化版本：r'question/\d+/\d+\.shtml'</span>
    link_detail <span class="token operator">=</span> LinkExtractor<span class="token punctuation">(</span>allow<span class="token operator">=</span><span class="token string">r'question/\d+/\d+\.shtml'</span><span class="token punctuation">)</span>  <span class="token comment">#提取详情页url</span>

    <span class="token comment">#规则解析器</span>
    <span class="token comment">#作用：获取连接提取器取到的连接，然后对其进行请求发送，根据指定规则对请求到的页面源码数据进行数据解析</span>
    rules <span class="token operator">=</span> <span class="token punctuation">(</span>
        <span class="token comment">#实例化一个Rule对象, 这里的follow如果是False，那么只加载起始页的下方的页码连接，如果是True则可以获取每一页的下方的页码url</span>
        <span class="token comment">#且可自动去重，也就是说所有的页码都会获取到</span>
        Rule<span class="token punctuation">(</span>link<span class="token punctuation">,</span> callback<span class="token operator">=</span><span class="token string">'parse_item'</span><span class="token punctuation">,</span> follow<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 匹配到每一页url并获得response后，调用parse_item解析函数，获得每个tr</span>

        <span class="token comment">#匹配每一tr对应的response，然后调用回调函数解析正文内容</span>
        Rule<span class="token punctuation">(</span>link_detail<span class="token punctuation">,</span>callback<span class="token operator">=</span><span class="token string">'parse_detail'</span><span class="token punctuation">,</span>follow<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token comment"># 不需要检测每个详情页的页码，但是一般页匹配不到提取规则</span>
    <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">parse_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        tr_list <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//*[@id=&quot;morelist&quot;]/div/table[2]//tr/td/table//tr'</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> tr <span class="token keyword">in</span> tr_list<span class="token punctuation">:</span>
            title <span class="token operator">=</span> tr<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./td[2]/a[2]/@title'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            status <span class="token operator">=</span> tr<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./td[3]/span/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            num <span class="token operator">=</span> tr<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./td[1]/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment"># 使用item 记录每个二级页面的新闻标签</span>
            item <span class="token operator">=</span> SunproItem_second<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span> <span class="token operator">=</span> title
            item<span class="token punctuation">[</span><span class="token string">'status'</span><span class="token punctuation">]</span> <span class="token operator">=</span> status
            item<span class="token punctuation">[</span><span class="token string">'num'</span><span class="token punctuation">]</span> <span class="token operator">=</span> num
            <span class="token keyword">yield</span>  item


    <span class="token comment"># 注意：之前我们做深度爬取的时候，通过meta传递item，可以使每条跨页面数据共用一个item，但是现在由于Rule规则</span>
    <span class="token comment">#作用，是我们不能使用meta传递参数，因为之前使scrap.Request类中的回调和meta元数据，但这里的Rule显然没有那种功能，</span>

    <span class="token comment">#解决办法：各自存储一个item，同过唯一键进行连接绑定存储</span>
    <span class="token keyword">def</span> <span class="token function">parse_detail</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 不能出现tbody，不然匹配不到content数据</span>
        content <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'/html/body/div[9]/table[2]//tr[1]//text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>
        content <span class="token operator">=</span> <span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>content<span class="token punctuation">)</span>
        num <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'/html/body/div[9]/table[1]//tr/td[2]/span[2]/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> num<span class="token punctuation">:</span>
            num <span class="token operator">=</span> num<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">':'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
            <span class="token comment"># 使用item，记录正文</span>
            item <span class="token operator">=</span> SunproItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">'num'</span><span class="token punctuation">]</span> <span class="token operator">=</span> num
            item<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span> <span class="token operator">=</span> content
            <span class="token keyword">yield</span>  item
            
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
 <span class="token comment">#settings.py文件</span>
ITEM_PIPELINES <span class="token operator">=</span> <span class="token punctuation">{</span>
   <span class="token string">'sunPro.pipelines.SunproPipeline'</span><span class="token punctuation">:</span> <span class="token number">300</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>
ROBOTSTXT_OBEY <span class="token operator">=</span> <span class="token boolean">False</span>
LOG_LEVEL <span class="token operator">=</span> <span class="token string">'ERROR'</span>
BOT_NAME <span class="token operator">=</span> <span class="token string">'sunPro'</span>

SPIDER_MODULES <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'sunPro.spiders'</span><span class="token punctuation">]</span>
NEWSPIDER_MODULE <span class="token operator">=</span> <span class="token string">'sunPro.spiders'</span>

USER_AGENT <span class="token operator">=</span> <span class="token string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/76.0.3809.132 Safari/537.36'</span>
</code></pre></div></li></ul> <h2 id="分布式爬虫"><a href="#分布式爬虫" class="header-anchor">#</a> 分布式爬虫</h2> <p>**什么是分布式爬虫？：**基于多台电脑组件一个分布式机群，然后让机群中的每一台电脑执行同一组程序，然后让它们对同一个网站的数据进行分布爬取(各自爬各自的，爬过的就不会再爬了)</p> <p><strong>为什么要使用分布式爬虫</strong>：提升爬取数据的效率</p> <p><strong>如何实现分布式爬虫：</strong></p> <ul><li><p>基于scrapy+redis的形式实现分布式：scrapy结合着scrapy-redis组件实现分布式</p></li> <li><p>原生的scrapy框架是无法实现分布式的！</p> <div class="language- extra-class"><pre class="language-text"><code>scrapy框架是否可以自己实现分布式？不可以。原因有二。
　　其一：因为多台机器上部署的scrapy会各自拥有各自的调度器，这样就使得多台机器无法分配start_urls列表中的url。（多台机器无法共享同一个调度器）
　　其二：多台机器爬取到的数据无法通过同一个管道对数据进行统一的数据持久出存储。（多台机器无法共享同一个管道）
</code></pre></div></li> <li><p>环境安装</p> <div class="language- extra-class"><pre class="language-text"><code>1、下载redis
2、pip install  scrapy-redis
</code></pre></div></li></ul> <h4 id="基于scrapy-redis组件的分布式爬虫"><a href="#基于scrapy-redis组件的分布式爬虫" class="header-anchor">#</a> 基于scrapy-redis组件的分布式爬虫</h4> <ul><li><p>scrapy-redis组件中为我们封装好了可以被多台机器共享的调度器和管道，我们可以直接使用并实现分布式数据爬取。</p> <ul><li>实现方式：</li></ul> <p>​            1.基于该组件的RedisSpider类</p> <p>​            2.基于该组件的RedisCrawlSpider类</p></li> <li><p>实现流程：</p> <ul><li><p>创建一个工程</p></li> <li><p>创建一个爬虫文件：基于CrawlSpider的爬虫文件</p> <div class="language-shell extra-class"><pre class="language-shell"><code><span class="token number">1</span>、<span class="token punctuation">\</span>scrapy学习<span class="token operator">&gt;</span>  scrapy startproject fbsPro
<span class="token number">2</span>、<span class="token punctuation">\</span>scrapy学习<span class="token punctuation">\</span>fbsPro<span class="token operator">&gt;</span>  scrapy genspider -t crawl fbs www.xxx.com
</code></pre></div></li> <li><p>修改爬虫文件</p> <ul><li><p>导包：from scrapy_redis.spiders import RedisCrawlSpider</p></li> <li><p>将当亲爬虫类的父类修改继承为RedisCrawlSpider，当然也可以继承RedisSpider，我们这就以CrawlSpider为例</p></li> <li><p>将start_urls替换成redis_key</p> <div class="language- extra-class"><pre class="language-text"><code>为什么要将start_url替换成redis_key?
  答：首先我们知道redis_key是一个队列，是一个分配任务的队列，我们之前的项目中爬虫对象spider一开始就从start_url中提取到主页中额页码url，然后将每个页码url封装成请求对象，到调度器中过滤等，再分布式中我们使用的是一个调度器，如果每台机器都从start_url中获取url然后发给调度器，这样调度器的压力就很大，我们其实只需要机群中的任意一台机器发起start_url请求就可以得到所有的页码对象了，这样调度器就没有过多压力再去重问题上，换句话说其他的机器就只需要守着redis_key队列，争抢任务就是了
</code></pre></div></li> <li><p>编写爬虫类爬取数据的操作</p></li> <li><p>在配置文件中进行相关配置，开启使用scrapy-redis组件中封装好的管道</p> <div class="language- extra-class"><pre class="language-text"><code>ITEM_PIPELINES = {
    'scrapy_redis.pipelines.RedisPipeline': 400
}
</code></pre></div><p><img src="data:image/gif;base64,R0lGODlhAQABAPABAP///wAAACH5BAEKAAAALAAAAAABAAEAAAICRAEAOw==" alt="点击并拖拽以移动">在配置文件中进行相关配置，开启使用scrapy-redis组件中封装好的调度器</p> <div class="language- extra-class"><pre class="language-text"><code># 使用scrapy-redis组件的去重队列
DUPEFILTER_CLASS = &quot;scrapy_redis.dupefilter.RFPDupeFilter&quot;
# 使用scrapy-redis组件自己的调度器
SCHEDULER = &quot;scrapy_redis.scheduler.Scheduler&quot;
# 是否允许暂停
SCHEDULER_PERSIST = True
</code></pre></div><p>在配置文件中进行爬虫程序链接redis的配置：</p> <div class="language- extra-class"><pre class="language-text"><code>REDIS_HOST = 'redis服务的ip地址'
REDIS_PORT = 6379
REDIS_ENCODING = ‘utf-8’
REDIS_PARAMS = {‘password’:’123456’}
</code></pre></div></li> <li><p>开启redis服务器：redis-server 配置文件</p> <div class="language- extra-class"><pre class="language-text"><code>打开redis.winds.conf文件
	1、注释掉：bind 127.0.0.1 否则其他人无法访问
	2、protected-mode no

重启redis服务：
	在cmd中：执行i&gt; ./redis-server redis.windows.conf
</code></pre></div></li> <li><p>开启redis客户端：redis-cli</p></li> <li><p>运行爬虫文件：scrapy runspider SpiderFile</p></li> <li><p>向调度器队列中扔入一个起始url（在redis客户端中操作）：lpush redis_key属性值 起始url</p> <div class="language- extra-class"><pre class="language-text"><code>可设置CONCURRENT_REQUESTS =2 放慢爬取速度
</code></pre></div></li> <li><p>向调度器中仍入一个其实url：程序执行一段后会夯住，需要我们给以个url</p> <ul><li><p>队列在哪？ 答：队列在redis中</p> <div class="language-shell extra-class"><pre class="language-shell"><code>redis客户端 <span class="token operator">&gt;</span> lpush fbsQueue www.xxx.com  <span class="token comment">#这样就向队列中放入了起始页，返回数据后，parse会解析出其余的页码url</span>

lpush + 队列名 + 起始页url
</code></pre></div></li></ul></li></ul></li> <li><p>爬取阳光热线：爬取所有页码对应的页面标题</p> <div class="language-python extra-class"><pre class="language-python"><code>爬虫文件
<span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>linkextractors <span class="token keyword">import</span> LinkExtractor
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>spiders <span class="token keyword">import</span> CrawlSpider<span class="token punctuation">,</span> Rule
<span class="token keyword">from</span> scrapy_redis<span class="token punctuation">.</span>spiders <span class="token keyword">import</span> RedisCrawlSpider
<span class="token keyword">from</span> fbsPro<span class="token punctuation">.</span>items <span class="token keyword">import</span> FbsproItem

<span class="token comment">#继承redis的爬虫类</span>
<span class="token keyword">class</span> <span class="token class-name">FbsSpider</span><span class="token punctuation">(</span>RedisCrawlSpider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'fbs'</span>
    <span class="token comment"># allowed_domains = ['www.xxx.com']</span>

    <span class="token comment"># start_urls = ['http://www.xxx.com/']</span>
    <span class="token comment">#不需要start_urls,替换为redis_key,</span>
    <span class="token comment">#表示的是可被共享调度器中的队列的名称，是用来存储经过调度器中过滤器过滤去重后的数据对象</span>
    redis_key <span class="token operator">=</span> <span class="token string">'fbsQueue'</span>

    rules <span class="token operator">=</span> <span class="token punctuation">(</span>
        <span class="token comment">#爬取页码url</span>
        Rule<span class="token punctuation">(</span>LinkExtractor<span class="token punctuation">(</span>allow<span class="token operator">=</span><span class="token string">r'type=4&amp;page=\d+'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> callback<span class="token operator">=</span><span class="token string">'parse_item'</span><span class="token punctuation">,</span> follow<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">parse_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        tr_list <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//*[@id=&quot;morelist&quot;]/div/table[2]//tr/td/table//tr'</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> tr <span class="token keyword">in</span> tr_list<span class="token punctuation">:</span>
            title <span class="token operator">=</span> tr<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./td[2]/a[2]/@title'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            status <span class="token operator">=</span> tr<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./td[3]/span/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item <span class="token operator">=</span> FbsproItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
            item<span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span> <span class="token operator">=</span> title
            item<span class="token punctuation">[</span><span class="token string">'status'</span><span class="token punctuation">]</span> <span class="token operator">=</span> status
            <span class="token keyword">yield</span> item

<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
 <span class="token comment">#items.py文件，根本用户到pipe</span>
<span class="token keyword">import</span> scrapy
<span class="token keyword">class</span> <span class="token class-name">FbsproItem</span><span class="token punctuation">(</span>scrapy<span class="token punctuation">.</span>Item<span class="token punctuation">)</span><span class="token punctuation">:</span>
     title <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
     status <span class="token operator">=</span> scrapy<span class="token punctuation">.</span>Field<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
 <span class="token comment">#pipelines.py文件</span>
<span class="token keyword">class</span> <span class="token class-name">FbsproPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> item
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>
 <span class="token comment">#settings.py文件</span>
ROBOTSTXT_OBEY <span class="token operator">=</span> <span class="token boolean">False</span>
<span class="token comment">#开启可以被共享的管道,意味着item提交给它</span>
ITEM_PIPELINES <span class="token operator">=</span> <span class="token punctuation">{</span>
    <span class="token string">'scrapy_redis.pipelines.RedisPipeline'</span><span class="token punctuation">:</span> <span class="token number">400</span>
<span class="token punctuation">}</span>

<span class="token comment">#指定使用可被共享的调度器</span>
<span class="token comment"># 增加了一个去重容器类的配置, 作用使用Redis的set集合来存储请求的指纹数据, 从而实现请求去重的持久化</span>
DUPEFILTER_CLASS <span class="token operator">=</span> <span class="token string">&quot;scrapy_redis.dupefilter.RFPDupeFilter&quot;</span>  <span class="token comment">#去重</span>

<span class="token comment"># 使用scrapy-redis组件自己的调度器</span>
SCHEDULER <span class="token operator">=</span> <span class="token string">&quot;scrapy_redis.scheduler.Scheduler&quot;</span>

<span class="token comment"># 配置调度器是否要持久化, 也就是当爬虫结束了, 要不要清空Redis中请求队列和去重指纹的set。如果是True, 就表示要持久化存储, 就不清空数据, 否则清空数据</span>
SCHEDULER_PERSIST <span class="token operator">=</span> <span class="token boolean">True</span>

<span class="token comment">#指定redis，局域网可以访问</span>
REDIS_HOST <span class="token operator">=</span> <span class="token string">'192.168.11.175'</span>
REDIS_PORT <span class="token operator">=</span> <span class="token number">6379</span>
</code></pre></div></li></ul></li></ul> <h4 id="scrapy中间件详解"><a href="#scrapy中间件详解" class="header-anchor">#</a> Scrapy中间件详解</h4> <p>​	中间件是Scrapy里面的一个核心概念。使用中间件可以在爬虫的请求发起之前或者请求返回之后对数据进行定制化修改，从而开发出适应不同情况的爬虫。“中间件”这个中文名字和前面章节讲到的“中间人”只有一字之差。它们做的事情确实也非常相似。中间件和中间人都能在中途劫持数据，做一些修改再把数据传递出去。不同点在于，中间件是开发者主动加进去的组件，而中间人是被动的，一般是恶意地加进去的环节。中间件主要用来辅助开发，而中间人却多被用来进行数据的窃取、伪造甚至攻击。</p> <p><strong>在Scrapy中有两种中间件</strong>：下载器中间件（Downloader Middleware）和爬虫中间件（Spider Middleware）。</p> <p>下载中间件： 官方解读，下载器中间件是介于Scrapy的request/response处理的钩子框架，是用于全局修改Scrapy request和response的一个轻量、底层的系统。这个介绍看起来非常绕口，但其实用容易理解的话表述就是：更换代理IP，更换Cookies，更换User-Agent，自动重试。</p> <ul><li><p>自定义代理中间件：</p> <p>Scrapy自动生成的这个文件名称为middlewares.py，名字后面的s表示复数，说明这个文件里面可以放很多个中间件。Scrapy自动创建的这个中间件是一个爬虫中间件，除了自带的中间件，我们可以自定义中间件，比如：开发代理中间件</p> <div class="language-python extra-class"><pre class="language-python"><code> <span class="token comment">#在middlewares.py中添加下面一段代码</span>
<span class="token keyword">class</span> <span class="token class-name">ProxyMiddleware</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment">#每个请求进来都要经过此函数，前提是注册了此类</span>
    <span class="token keyword">def</span> <span class="token function">process_request</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        proxy <span class="token operator">=</span> random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>settings<span class="token punctuation">[</span><span class="token string">'PROXIES'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        request<span class="token punctuation">.</span>meta<span class="token punctuation">[</span><span class="token string">'proxy'</span><span class="token punctuation">]</span> <span class="token operator">=</span> proxy
</code></pre></div><p>要修改请求的代理，就需要在请求的meta里面添加一个Key为proxy，Value为代理IP的项。</p> <p>由于用到了random和settings，所以需要在middlewares.py开头导入它们：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> random
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>conf <span class="token keyword">import</span> settings  <span class="token comment">#配置了settings文件</span>
</code></pre></div><p>在下载器中间件里面有一个名为<code>process_request()</code>的方法，这个方法中的代码会在每次爬虫访问网页之前执行。打开settings.py，首先添加几个代理IP：</p> <div class="language-PYTHON extra-class"><pre class="language-python"><code>PROXIES <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'https://114.217.243.25:8118'</span><span class="token punctuation">,</span>
          <span class="token string">'https://125.37.175.233:8118'</span><span class="token punctuation">,</span>
          <span class="token string">'http://1.85.116.218:8118'</span><span class="token punctuation">]</span>
          
          <span class="token comment">#需要注意的是，代理IP是有类型的，需要先看清楚是HTTP型的代理IP还是HTTPS型的代理IP。如果用错了，就会导致无法访问。</span>
        
 <span class="token comment">#解除注释并修改，从而引用ProxyMiddleware。修改为：</span>
DOWNLOADER_MIDDLEWARES <span class="token operator">=</span> <span class="token punctuation">{</span>
  <span class="token string">'AdvanceSpider.middlewares.ProxyMiddleware'</span><span class="token punctuation">:</span> <span class="token number">543</span><span class="token punctuation">,</span>
<span class="token punctuation">}</span>
</code></pre></div><p>​	不为人知的scrapy自带的中间件：Scrapy其实自带了UA中间件（UserAgentMiddleware）、代理中间件（HttpProxyMiddleware）和重试中间件（RetryMiddleware）。所以，从“原则上”说，要自己开发这3个中间件，需要先禁用Scrapy里面自带的这3个中间件。要禁用Scrapy的中间件，需要在settings.py里面将这个中间件的顺序设为None：</p> <div class="language-python extra-class"><pre class="language-python"><code>DOWNLOADER_MIDDLEWARES <span class="token operator">=</span> <span class="token punctuation">{</span>
  <span class="token string">'AdvanceSpider.middlewares.ProxyMiddleware'</span><span class="token punctuation">:</span> <span class="token number">543</span><span class="token punctuation">,</span>
  <span class="token string">'scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware'</span><span class="token punctuation">:</span> <span class="token boolean">None</span><span class="token punctuation">,</span>
  <span class="token string">'scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware'</span><span class="token punctuation">:</span> <span class="token boolean">None</span>
<span class="token punctuation">}</span>
</code></pre></div></li> <li><p>自定义UA中间件：</p> <p>开发UA中间件和开发代理中间件几乎一样，它也是从settings.py配置好的UA列表中随机选择一项，加入到请求头中。代码如下：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">UAMiddleware</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">process_request</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        ua <span class="token operator">=</span> random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>settings<span class="token punctuation">[</span><span class="token string">'USER_AGENT_LIST'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment">#在settting中配置</span>
        request<span class="token punctuation">.</span>headers<span class="token punctuation">[</span><span class="token string">'User-Agent'</span><span class="token punctuation">]</span> <span class="token operator">=</span> ua
</code></pre></div><p>比IP更好的是，UA不会存在失效的问题，所以只要收集几十个UA，就可以一直使用</p></li> <li><p>自定义Cookie中间件：</p> <p>首先开发一个小程序，通过Selenium登录这个页面，并将网站返回的Headers保存到Redis中。这个小程序的代码如下图所示。</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> time
<span class="token keyword">import</span> json
<span class="token keyword">import</span> redis
<span class="token keyword">from</span> selenium <span class="token keyword">import</span> webdriver

<span class="token comment"># 获取redis连接对象</span>
client <span class="token operator">=</span> redis<span class="token punctuation">.</span>StrictRedis<span class="token punctuation">(</span><span class="token punctuation">)</span>

driver <span class="token operator">=</span> webdriver<span class="token punctuation">.</span>Chrome<span class="token punctuation">(</span>executable_path<span class="token operator">=</span><span class="token string">r'D:\21期\爬虫 + 数据分析\tools\chromedriver.exe'</span><span class="token punctuation">)</span>
driver<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'http://exercise.kingname.info/exercise_login_success'</span><span class="token punctuation">)</span>

user <span class="token operator">=</span> driver<span class="token punctuation">.</span>find_element_by_xpath<span class="token punctuation">(</span><span class="token string">'//input[@name=&quot;username&quot;]'</span><span class="token punctuation">)</span>
user<span class="token punctuation">.</span>clear<span class="token punctuation">(</span><span class="token punctuation">)</span>
user<span class="token punctuation">.</span>send_keys<span class="token punctuation">(</span><span class="token string">'kingname'</span><span class="token punctuation">)</span>

user <span class="token operator">=</span> driver<span class="token punctuation">.</span>find_element_by_xpath<span class="token punctuation">(</span><span class="token string">'//input[@name=&quot;password&quot;]'</span><span class="token punctuation">)</span>
user<span class="token punctuation">.</span>clear<span class="token punctuation">(</span><span class="token punctuation">)</span>
user<span class="token punctuation">.</span>send_keys<span class="token punctuation">(</span><span class="token string">'genius'</span><span class="token punctuation">)</span>

rember <span class="token operator">=</span> driver<span class="token punctuation">.</span>find_element_by_xpath<span class="token punctuation">(</span><span class="token string">'//input[@name=&quot;rememberme&quot;]'</span><span class="token punctuation">)</span>
rember<span class="token punctuation">.</span>click<span class="token punctuation">(</span><span class="token punctuation">)</span>

login <span class="token operator">=</span> driver<span class="token punctuation">.</span>find_element_by_xpath<span class="token punctuation">(</span><span class="token string">'//button[@class=&quot;login&quot;]'</span><span class="token punctuation">)</span>
login<span class="token punctuation">.</span>click<span class="token punctuation">(</span><span class="token punctuation">)</span>

time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
cookies <span class="token operator">=</span> driver<span class="token punctuation">.</span>get_cookies<span class="token punctuation">(</span><span class="token punctuation">)</span>
client<span class="token punctuation">.</span>lpush<span class="token punctuation">(</span><span class="token string">'cookies'</span><span class="token punctuation">,</span>json<span class="token punctuation">.</span>dumps<span class="token punctuation">(</span>cookies<span class="token punctuation">)</span><span class="token punctuation">)</span>
driver<span class="token punctuation">.</span>quit<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><p>​      这段代码的作用是使用Selenium和ChromeDriver填写用户名和密码，实现登录练习页面，然后将登录以后的Cookies转换为JSON格式的字符串并保存到Redis中。</p> <p>接下来，再写一个中间件，用来从Redis中读取Cookies，并把这个Cookies给Scrapy使用，并且在settings.py文件中修改中间件配置文件</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> scrapy <span class="token keyword">import</span> signals
<span class="token keyword">import</span> redis<span class="token punctuation">,</span>json

<span class="token keyword">class</span> <span class="token class-name">LoginMiddleware</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 每次请求chong</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>client <span class="token operator">=</span> redis<span class="token punctuation">.</span>StrictRedis<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_request</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>request<span class="token punctuation">,</span>spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># 过滤爬虫文件名</span>
        <span class="token keyword">if</span> spider<span class="token punctuation">.</span>name <span class="token operator">==</span> <span class="token string">'spider'</span><span class="token punctuation">:</span>
            <span class="token comment">#获得redis中的数据，第二次得重新运行selenium文件将cookie存入才可用</span>
            cookies <span class="token operator">=</span> json<span class="token punctuation">.</span>loads<span class="token punctuation">(</span>self<span class="token punctuation">.</span>client<span class="token punctuation">.</span>lpop<span class="token punctuation">(</span><span class="token string">'cookies'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>decode<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span>cookies<span class="token punctuation">)</span>
            request<span class="token punctuation">.</span>cookies <span class="token operator">=</span> cookies
</code></pre></div><p>设置了这个中间件以后，爬虫里面的代码不需要做任何修改就可以成功得到登录以后才能看到的HTML</p></li> <li><p>中间件中集成Selenium：</p> <p>​     对于一些很麻烦的异步加载页面，手动寻找它的后台API代价可能太大。这种情况下可以使用Selenium和ChromeDriver或者Selenium和PhantomJS来实现渲染网页。</p> <p>这是前面的章节已经讲到的内容。那么，如何把Scrapy与Selenium结合起来呢？这个时候又要用到中间件了。</p> <p>创建一个SeleniumMiddleware，其代码如下：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>http <span class="token keyword">import</span> HtmlResponse
<span class="token keyword">class</span> <span class="token class-name">SeleniumMiddleware</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>driver <span class="token operator">=</span> webdriver<span class="token punctuation">.</span>Chrome<span class="token punctuation">(</span><span class="token string">'./chromedriver'</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">process_request</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> request<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> spider<span class="token punctuation">.</span>name <span class="token operator">==</span> <span class="token string">'seleniumSpider'</span><span class="token punctuation">:</span>
            self<span class="token punctuation">.</span>driver<span class="token punctuation">.</span>get<span class="token punctuation">(</span>request<span class="token punctuation">.</span>url<span class="token punctuation">)</span>
            time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span>
            body <span class="token operator">=</span> self<span class="token punctuation">.</span>driver<span class="token punctuation">.</span>page_source
        <span class="token keyword">return</span> HtmlResponse<span class="token punctuation">(</span>self<span class="token punctuation">.</span>driver<span class="token punctuation">.</span>current_url<span class="token punctuation">,</span>
                           body<span class="token operator">=</span>body<span class="token punctuation">,</span>
                           encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">,</span>
                           request<span class="token operator">=</span>request<span class="token punctuation">)</span>
</code></pre></div><p>这个中间件的作用，就是对名为“seleniumSpider”的爬虫请求的网址，使用ChromeDriver先进行渲染，然后用返回的渲染后的HTML代码构造一个Response对象</p></li></ul> <h2 id="增量式爬虫"><a href="#增量式爬虫" class="header-anchor">#</a> 增量式爬虫</h2> <p>​	当我们在浏览相关网页的时候会发现，某些网站定时会在原有网页数据的基础上更新一批数据，例如某电影网站会实时更新一批最近热门的电影。小说网站会根据作者创作的进度实时更新最新的章节数据等等。那么，类似的情景，当我们在爬虫的过程中遇到时，我们是不是需要定时更新程序以便能爬取到网站中最近更新的数据呢？</p> <ul><li><p>概念：通过爬虫程序监测某网站数据更新的情况，以便可以爬取到该网站更新出的新数据。</p></li> <li><p>如何进行增量式的爬取工作：</p> <ul><li><p>在发送请求之前判断这个URL是不是之前爬取过</p></li> <li><p>在解析内容后判断这部分内容是不是之前爬取过</p></li> <li><p>写入存储介质时判断内容是不是已经在介质中存在</p> <p>分析：不难发现，其实增量爬取的核心是<strong>去重</strong>， 至于去重的操作在哪个步骤起作用，只能说各有利弊。在我看来，前两种思路需要根据实际情况取一个（也可能都用）。第一种思路适合不断有新页面出现的网站，比如说小说的新章节，每天的最新新闻等等；第二种思路则适合页面内容会更新的网站。第三个思路是相当于是最后的一道防线。这样做可以最大程度上达到去重的目的。</p></li></ul></li> <li><p>去重方法</p> <ul><li>将爬取过程中产生的url进行存储，存储在redis的set中。当下次进行数据爬取时，首先对即将要发起的请求对应的url在存储的url的set中做判断，如果存在则不进行请求，否则才进行请求。</li> <li>对爬取到的网页内容进行唯一标识的制定，然后将该唯一表示存储至redis的set中。当下次爬取到网页数据的时候，在进行持久化存储之前，首先可以先判断该数据的唯一标识在redis的set中是否存在，在决定是否进行持久化存储。</li></ul></li> <li><p>简单示例：</p> <div class="language-python extra-class"><pre class="language-python"><code>爬虫文件：
<span class="token keyword">import</span> scrapy
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>linkextractors <span class="token keyword">import</span> LinkExtractor
<span class="token keyword">from</span> scrapy<span class="token punctuation">.</span>spiders <span class="token keyword">import</span> CrawlSpider<span class="token punctuation">,</span> Rule

<span class="token keyword">from</span> redis <span class="token keyword">import</span> Redis
<span class="token keyword">from</span> incrementPro<span class="token punctuation">.</span>items <span class="token keyword">import</span> IncrementproItem
<span class="token keyword">class</span> <span class="token class-name">MovieSpider</span><span class="token punctuation">(</span>CrawlSpider<span class="token punctuation">)</span><span class="token punctuation">:</span>
    name <span class="token operator">=</span> <span class="token string">'movie'</span>
    <span class="token comment"># allowed_domains = ['www.xxx.com']</span>
    start_urls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'http://www.4567tv.tv/frim/index7-11.html'</span><span class="token punctuation">]</span>

    rules <span class="token operator">=</span> <span class="token punctuation">(</span>
        Rule<span class="token punctuation">(</span>LinkExtractor<span class="token punctuation">(</span>allow<span class="token operator">=</span><span class="token string">r'/frim/index7-\d+\.html'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> callback<span class="token operator">=</span><span class="token string">'parse_item'</span><span class="token punctuation">,</span> follow<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">)</span>
    <span class="token comment">#创建redis链接对象</span>
    conn <span class="token operator">=</span> Redis<span class="token punctuation">(</span>host<span class="token operator">=</span><span class="token string">'127.0.0.1'</span><span class="token punctuation">,</span>port<span class="token operator">=</span><span class="token number">6379</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">parse_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        li_list <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//li[@class=&quot;p1 m1&quot;]'</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> li <span class="token keyword">in</span> li_list<span class="token punctuation">:</span>
            <span class="token comment">#获取详情页的url</span>
            detail_url <span class="token operator">=</span> <span class="token string">'http://www.4567tv.tv'</span><span class="token operator">+</span>li<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'./a/@href'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token comment">#将详情页的url存入redis的set中，通过redis的set进行去重判断</span>
            ex <span class="token operator">=</span> self<span class="token punctuation">.</span>conn<span class="token punctuation">.</span>sadd<span class="token punctuation">(</span><span class="token string">'urls'</span><span class="token punctuation">,</span>detail_url<span class="token punctuation">)</span>
            <span class="token keyword">if</span> ex <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'该url没有被爬取过，可以进行数据的爬取'</span><span class="token punctuation">)</span>
                <span class="token keyword">yield</span> scrapy<span class="token punctuation">.</span>Request<span class="token punctuation">(</span>url<span class="token operator">=</span>detail_url<span class="token punctuation">,</span>callback<span class="token operator">=</span>self<span class="token punctuation">.</span>parst_detail<span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'数据还没有更新，暂无新数据可爬取！'</span><span class="token punctuation">)</span>

    <span class="token comment">#解析详情页中的电影名称和类型，进行持久化存储</span>
    <span class="token keyword">def</span> <span class="token function">parst_detail</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>response<span class="token punctuation">)</span><span class="token punctuation">:</span>
        item <span class="token operator">=</span> IncrementproItem<span class="token punctuation">(</span><span class="token punctuation">)</span>
        item<span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">]</span> <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//dt[@class=&quot;name&quot;]/text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract_first<span class="token punctuation">(</span><span class="token punctuation">)</span>
        item<span class="token punctuation">[</span><span class="token string">'kind'</span><span class="token punctuation">]</span> <span class="token operator">=</span> response<span class="token punctuation">.</span>xpath<span class="token punctuation">(</span><span class="token string">'//div[@class=&quot;ct-c&quot;]/dl/dt[4]//text()'</span><span class="token punctuation">)</span><span class="token punctuation">.</span>extract<span class="token punctuation">(</span><span class="token punctuation">)</span>
        item<span class="token punctuation">[</span><span class="token string">'kind'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">''</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>item<span class="token punctuation">[</span><span class="token string">'kind'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">yield</span> item
        
<span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span><span class="token operator">-</span>        
 <span class="token comment">#管道文件：</span>
<span class="token keyword">from</span> redis <span class="token keyword">import</span> Redis
<span class="token keyword">class</span> <span class="token class-name">IncrementproPipeline</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    conn <span class="token operator">=</span> <span class="token boolean">None</span>
    <span class="token keyword">def</span> <span class="token function">open_spider</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>conn <span class="token operator">=</span> Redis<span class="token punctuation">(</span>host<span class="token operator">=</span><span class="token string">'127.0.0.1'</span><span class="token punctuation">,</span>port<span class="token operator">=</span><span class="token number">6379</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">process_item</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> item<span class="token punctuation">,</span> spider<span class="token punctuation">)</span><span class="token punctuation">:</span>
        dic <span class="token operator">=</span> <span class="token punctuation">{</span>
            <span class="token string">'name'</span><span class="token punctuation">:</span>item<span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
            <span class="token string">'kind'</span><span class="token punctuation">:</span>item<span class="token punctuation">[</span><span class="token string">'kind'</span><span class="token punctuation">]</span>
        <span class="token punctuation">}</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>dic<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>conn<span class="token punctuation">.</span>lpush<span class="token punctuation">(</span><span class="token string">'movieData'</span><span class="token punctuation">,</span>dic<span class="token punctuation">)</span>
        <span class="token keyword">return</span> item
</code></pre></div></li></ul></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/python/spider/多任务协程.html" class="prev">
        多任务协程爬虫
      </a></span> <span class="next"><a href="/python/spider/Selenium记录.html">
        Selenium万能的自动化爬虫
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.51f2f156.js" defer></script><script src="/assets/js/2.8911ec45.js" defer></script><script src="/assets/js/107.7331bbca.js" defer></script>
  </body>
</html>
